2015-09-25 18:46:27 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginSuccess with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of successful kerberos logins and latency (milliseconds)])
2015-09-25 18:46:27 DEBUG MutableMetricsFactory:42 - field org.apache.hadoop.metrics2.lib.MutableRate org.apache.hadoop.security.UserGroupInformation$UgiMetrics.loginFailure with annotation @org.apache.hadoop.metrics2.annotation.Metric(about=, sampleName=Ops, always=false, type=DEFAULT, valueName=Time, value=[Rate of failed kerberos logins and latency (milliseconds)])
2015-09-25 18:46:27 DEBUG MetricsSystemImpl:220 - UgiMetrics, User and group related metrics
2015-09-25 18:46:27 DEBUG KerberosName:87 - Kerberos krb5 configuration not found, setting default realm to empty
2015-09-25 18:46:27 DEBUG Groups:180 -  Creating new Groups object
2015-09-25 18:46:27 DEBUG NativeCodeLoader:46 - Trying to load the custom-built native-hadoop library...
2015-09-25 18:46:27 DEBUG NativeCodeLoader:55 - Failed to load native-hadoop with error: java.lang.UnsatisfiedLinkError: no hadoop in java.library.path
2015-09-25 18:46:27 DEBUG NativeCodeLoader:56 - java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2015-09-25 18:46:27 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2015-09-25 18:46:27 DEBUG JniBasedUnixGroupsMappingWithFallback:40 - Falling back to shell based
2015-09-25 18:46:27 DEBUG JniBasedUnixGroupsMappingWithFallback:44 - Group mapping impl=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
2015-09-25 18:46:27 DEBUG Groups:66 - Group mapping impl=org.apache.hadoop.security.JniBasedUnixGroupsMappingWithFallback; cacheTimeout=300000
2015-09-25 18:46:27 DEBUG UserGroupInformation:177 - hadoop login
2015-09-25 18:46:27 DEBUG UserGroupInformation:126 - hadoop login commit
2015-09-25 18:46:27 DEBUG UserGroupInformation:156 - using local user:UnixPrincipal: aparna
2015-09-25 18:46:27 DEBUG UserGroupInformation:703 - UGI loginUser:aparna (auth:SIMPLE)
2015-09-25 18:46:27 INFO  SecurityManager:59 - Changing view acls to: aparna
2015-09-25 18:46:27 INFO  SecurityManager:59 - Changing modify acls to: aparna
2015-09-25 18:46:27 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(aparna); users with modify permissions: Set(aparna)
2015-09-25 18:46:27 DEBUG SSLOptions:63 - No SSL protocol specified
2015-09-25 18:46:27 DEBUG SSLOptions:63 - No SSL protocol specified
2015-09-25 18:46:27 DEBUG SSLOptions:63 - No SSL protocol specified
2015-09-25 18:46:27 DEBUG SecurityManager:63 - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-09-25 18:46:27 DEBUG SecurityManager:63 - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-09-25 18:46:27 INFO  HttpServer:59 - Starting HTTP Server
2015-09-25 18:46:27 DEBUG log:162 - Logging to org.slf4j.impl.Log4jLoggerAdapter(org.eclipse.jetty.util.log) via org.eclipse.jetty.util.log.Slf4jLog
2015-09-25 18:46:27 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@4c398c80 + SocketConnector@0.0.0.0:0 as connector
2015-09-25 18:46:27 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@4c398c80 + qtp173791568{8<=0<=0/254,-1} as threadpool
2015-09-25 18:46:27 DEBUG HttpServer:63 - HttpServer is not using security
2015-09-25 18:46:27 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.HandlerList@47404bea + org.eclipse.jetty.server.handler.ResourceHandler@305f7627 as handler
2015-09-25 18:46:27 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.HandlerList@47404bea + org.eclipse.jetty.server.handler.DefaultHandler@5d018107 as handler
2015-09-25 18:46:27 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@4c398c80 + org.eclipse.jetty.server.handler.HandlerList@47404bea as handler
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.Server@4c398c80
2015-09-25 18:46:27 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.HandlerList@47404bea
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.ResourceHandler@305f7627
2015-09-25 18:46:27 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.ResourceHandler@305f7627
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.ResourceHandler@305f7627
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.DefaultHandler@5d018107
2015-09-25 18:46:27 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.DefaultHandler@5d018107
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.DefaultHandler@5d018107
2015-09-25 18:46:27 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.HandlerList@47404bea
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.HandlerList@47404bea
2015-09-25 18:46:27 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.Server@4c398c80
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:179 - starting qtp173791568{8<=0<=0/254,-1}
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:172 - STARTED qtp173791568{8<=6<=8/254,0}
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:179 - starting SocketConnector@0.0.0.0:0
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:179 - starting null/null
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:172 - STARTED PooledBuffers [0/1024@6144,0/1024@16384,0/1024@-]/PooledBuffers [0/1024@6144,0/1024@32768,0/1024@-]
2015-09-25 18:46:27 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:42168
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:172 - STARTED SocketConnector@0.0.0.0:42168
2015-09-25 18:46:27 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.Server@4c398c80
2015-09-25 18:46:27 INFO  Utils:59 - Successfully started service 'HTTP class server' on port 42168.
2015-09-25 18:46:29 DEBUG SparkILoop:63 - Clearing 6 thunks.
2015-09-25 18:46:31 WARN  Utils:71 - Your hostname, aparna-Inspiron-5548 resolves to a loopback address: 127.0.1.1; using 192.168.0.18 instead (on interface wlan0)
2015-09-25 18:46:31 WARN  Utils:71 - Set SPARK_LOCAL_IP if you need to bind to another address
2015-09-25 18:46:31 INFO  SparkContext:59 - Running Spark version 1.5.0
2015-09-25 18:46:31 INFO  SecurityManager:59 - Changing view acls to: aparna
2015-09-25 18:46:31 INFO  SecurityManager:59 - Changing modify acls to: aparna
2015-09-25 18:46:31 INFO  SecurityManager:59 - SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(aparna); users with modify permissions: Set(aparna)
2015-09-25 18:46:31 DEBUG SSLOptions:63 - No SSL protocol specified
2015-09-25 18:46:31 DEBUG SSLOptions:63 - No SSL protocol specified
2015-09-25 18:46:31 DEBUG SSLOptions:63 - No SSL protocol specified
2015-09-25 18:46:31 DEBUG SecurityManager:63 - SSLConfiguration for file server: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-09-25 18:46:31 DEBUG SecurityManager:63 - SSLConfiguration for Akka: SSLOptions{enabled=false, keyStore=None, keyStorePassword=None, trustStore=None, trustStorePassword=None, protocol=None, enabledAlgorithms=Set()}
2015-09-25 18:46:31 DEBUG AkkaUtils:63 - In createActorSystem, requireCookie is: off
2015-09-25 18:46:31 INFO  Slf4jLogger:80 - Slf4jLogger started
2015-09-25 18:46:31 INFO  Remoting:74 - Starting remoting
2015-09-25 18:46:31 INFO  Remoting:74 - Remoting started; listening on addresses :[akka.tcp://sparkDriver@192.168.0.18:60863]
2015-09-25 18:46:31 INFO  Utils:59 - Successfully started service 'sparkDriver' on port 60863.
2015-09-25 18:46:31 DEBUG SparkEnv:63 - Using serializer: class org.apache.spark.serializer.JavaSerializer
2015-09-25 18:46:31 INFO  SparkEnv:59 - Registering MapOutputTracker
2015-09-25 18:46:31 INFO  SparkEnv:59 - Registering BlockManagerMaster
2015-09-25 18:46:31 INFO  DiskBlockManager:59 - Created local directory at /tmp/blockmgr-546388e9-aec9-4bec-9475-eb4bf2984a8e
2015-09-25 18:46:31 INFO  MemoryStore:59 - MemoryStore started with capacity 530.0 MB
2015-09-25 18:46:31 INFO  HttpFileServer:59 - HTTP File server directory is /tmp/spark-4c7d67c9-810d-4e5d-bd52-326b5610e6b6/httpd-f754008a-9dbe-426f-a395-a07cda905032
2015-09-25 18:46:31 INFO  HttpServer:59 - Starting HTTP Server
2015-09-25 18:46:31 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@a3b858f + SocketConnector@0.0.0.0:0 as connector
2015-09-25 18:46:31 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@a3b858f + qtp1611382686{8<=0<=0/254,-1} as threadpool
2015-09-25 18:46:31 DEBUG HttpServer:63 - HttpServer is not using security
2015-09-25 18:46:31 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.HandlerList@2475fba3 + org.eclipse.jetty.server.handler.ResourceHandler@19bf47fc as handler
2015-09-25 18:46:31 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.HandlerList@2475fba3 + org.eclipse.jetty.server.handler.DefaultHandler@71dd4624 as handler
2015-09-25 18:46:31 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@a3b858f + org.eclipse.jetty.server.handler.HandlerList@2475fba3 as handler
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.Server@a3b858f
2015-09-25 18:46:31 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.HandlerList@2475fba3
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.ResourceHandler@19bf47fc
2015-09-25 18:46:31 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.ResourceHandler@19bf47fc
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.ResourceHandler@19bf47fc
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.DefaultHandler@71dd4624
2015-09-25 18:46:31 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.DefaultHandler@71dd4624
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.DefaultHandler@71dd4624
2015-09-25 18:46:31 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.HandlerList@2475fba3
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.HandlerList@2475fba3
2015-09-25 18:46:31 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.Server@a3b858f
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:179 - starting qtp1611382686{8<=0<=0/254,-1}
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:172 - STARTED qtp1611382686{8<=7<=8/254,0}
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:179 - starting SocketConnector@0.0.0.0:0
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:179 - starting null/null
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:172 - STARTED PooledBuffers [0/1024@6144,0/1024@16384,0/1024@-]/PooledBuffers [0/1024@6144,0/1024@32768,0/1024@-]
2015-09-25 18:46:31 INFO  AbstractConnector:338 - Started SocketConnector@0.0.0.0:54441
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:172 - STARTED SocketConnector@0.0.0.0:54441
2015-09-25 18:46:31 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.Server@a3b858f
2015-09-25 18:46:31 INFO  Utils:59 - Successfully started service 'HTTP file server' on port 54441.
2015-09-25 18:46:31 DEBUG HttpFileServer:63 - HTTP file server started at: http://192.168.0.18:54441
2015-09-25 18:46:31 INFO  SparkEnv:59 - Registering OutputCommitCoordinator
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-15e08615}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-15e08615=org.apache.spark.ui.JettyUtils$$anon$1-15e08615}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-4276ad40}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4276ad40=org.apache.spark.ui.JettyUtils$$anon$1-4276ad40}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-18715bb}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-18715bb=org.apache.spark.ui.JettyUtils$$anon$1-18715bb}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe=org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-7d284f15}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7d284f15=org.apache.spark.ui.JettyUtils$$anon$1-7d284f15}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6=org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3303e89e}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3303e89e=org.apache.spark.ui.JettyUtils$$anon$1-3303e89e}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-cec590c}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-cec590c=org.apache.spark.ui.JettyUtils$$anon$1-cec590c}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-21090c88}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-21090c88=org.apache.spark.ui.JettyUtils$$anon$1-21090c88}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-d62472f}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-d62472f=org.apache.spark.ui.JettyUtils$$anon$1-d62472f}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70=org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0=org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd=org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33=org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-a826ff8}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-a826ff8=org.apache.spark.ui.JettyUtils$$anon$1-a826ff8}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-71f0806b}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-71f0806b=org.apache.spark.ui.JettyUtils$$anon$1-71f0806b}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-79ad1774}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-79ad1774=org.apache.spark.ui.JettyUtils$$anon$1-79ad1774}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6=org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3=org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-63187d63}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-63187d63=org.apache.spark.ui.JettyUtils$$anon$1-63187d63}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.eclipse.jetty.servlet.DefaultServlet-7996d0d4}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.eclipse.jetty.servlet.DefaultServlet-7996d0d4=org.eclipse.jetty.servlet.DefaultServlet-7996d0d4}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-4243341e}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-4243341e=org.apache.spark.ui.JettyUtils$$anon$2-4243341e}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/*=com.sun.jersey.spi.container.servlet.ServletContainer-3b021664}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={com.sun.jersey.spi.container.servlet.ServletContainer-3b021664=com.sun.jersey.spi.container.servlet.ServletContainer-3b021664}
2015-09-25 18:46:31 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:31 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:31 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:31 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22}
2015-09-25 18:46:31 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22=org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22}
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@26ffd2c0 + SelectChannelConnector@0.0.0.0:4040 as connector
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@26ffd2c0 + qtp220774932{8<=0<=0/254,-1} as threadpool
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@7cca31fc + o.e.j.s.ServletContextHandler{/jobs,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@619c3546 + o.e.j.s.ServletContextHandler{/jobs/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@29090809 + o.e.j.s.ServletContextHandler{/jobs/job,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@30cafd13 + o.e.j.s.ServletContextHandler{/jobs/job/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@1d226f27 + o.e.j.s.ServletContextHandler{/stages,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@1d944fc0 + o.e.j.s.ServletContextHandler{/stages/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@7c3c453b + o.e.j.s.ServletContextHandler{/stages/stage,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@1b791dca + o.e.j.s.ServletContextHandler{/stages/stage/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@15ac02d5 + o.e.j.s.ServletContextHandler{/stages/pool,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@2af9a5ef + o.e.j.s.ServletContextHandler{/stages/pool/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@34f23816 + o.e.j.s.ServletContextHandler{/storage,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@6736f40f + o.e.j.s.ServletContextHandler{/storage/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@12f9f896 + o.e.j.s.ServletContextHandler{/storage/rdd,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@7548e1fb + o.e.j.s.ServletContextHandler{/storage/rdd/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@505f45cc + o.e.j.s.ServletContextHandler{/environment,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@994544 + o.e.j.s.ServletContextHandler{/environment/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@5df92089 + o.e.j.s.ServletContextHandler{/executors,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@6f0c45f4 + o.e.j.s.ServletContextHandler{/executors/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@45571cfc + o.e.j.s.ServletContextHandler{/executors/threadDump,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@faec277 + o.e.j.s.ServletContextHandler{/executors/threadDump/json,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@1b475663 + o.e.j.s.ServletContextHandler{/static,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@1669931a + o.e.j.s.ServletContextHandler{/,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@6b24ddd7 + o.e.j.s.ServletContextHandler{/api,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.GzipHandler@12e007be + o.e.j.s.ServletContextHandler{/stages/stage/kill,null} as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@7cca31fc as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@619c3546 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@29090809 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@30cafd13 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@1d226f27 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@1d944fc0 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@7c3c453b as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@1b791dca as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@15ac02d5 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@2af9a5ef as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@34f23816 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@6736f40f as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@12f9f896 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@7548e1fb as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@505f45cc as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@994544 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@5df92089 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@6f0c45f4 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@45571cfc as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@faec277 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@1b475663 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@1669931a as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@6b24ddd7 as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + org.eclipse.jetty.server.handler.GzipHandler@12e007be as handler
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.server.Server@26ffd2c0 + org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf as handler
2015-09-25 18:46:36 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.Server@26ffd2c0
2015-09-25 18:46:36 INFO  Server:272 - jetty-8.y.z-SNAPSHOT
2015-09-25 18:46:36 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf
2015-09-25 18:46:36 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@7cca31fc
2015-09-25 18:46:36 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:46:36 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@ee2ae9a + org.apache.spark.ui.JettyUtils$$anon$1-15e08615 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@ee2ae9a + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-15e08615 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/jobs,null} + org.eclipse.jetty.servlet.ServletHandler@ee2ae9a as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@ee2ae9a
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-15e08615}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-15e08615=org.apache.spark.ui.JettyUtils$$anon$1-15e08615}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@ee2ae9a
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@ee2ae9a
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-15e08615
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-15e08615
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@7cca31fc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@7cca31fc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@619c3546
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/jobs/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2e3252 + org.apache.spark.ui.JettyUtils$$anon$1-4276ad40 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2e3252 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-4276ad40 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/jobs/json,null} + org.eclipse.jetty.servlet.ServletHandler@2e3252 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@2e3252
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-4276ad40}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-4276ad40=org.apache.spark.ui.JettyUtils$$anon$1-4276ad40}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@2e3252
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@2e3252
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/jobs/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-4276ad40
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-4276ad40
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/jobs/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@619c3546
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@619c3546
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@29090809
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/jobs/job,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@77cddc0c + org.apache.spark.ui.JettyUtils$$anon$1-18715bb as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@77cddc0c + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-18715bb as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/jobs/job,null} + org.eclipse.jetty.servlet.ServletHandler@77cddc0c as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@77cddc0c
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-18715bb}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-18715bb=org.apache.spark.ui.JettyUtils$$anon$1-18715bb}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@77cddc0c
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@77cddc0c
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/jobs/job,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-18715bb
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-18715bb
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/jobs/job,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@29090809
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@29090809
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@30cafd13
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@671d97bc + org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@671d97bc + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/jobs/job/json,null} + org.eclipse.jetty.servlet.ServletHandler@671d97bc as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@671d97bc
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe=org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@671d97bc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@671d97bc
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-2a19a0fe
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/jobs/job/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@30cafd13
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@30cafd13
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@1d226f27
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/stages,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@774f2992 + org.apache.spark.ui.JettyUtils$$anon$1-7d284f15 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@774f2992 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-7d284f15 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/stages,null} + org.eclipse.jetty.servlet.ServletHandler@774f2992 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@774f2992
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-7d284f15}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-7d284f15=org.apache.spark.ui.JettyUtils$$anon$1-7d284f15}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@774f2992
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@774f2992
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/stages,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-7d284f15
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-7d284f15
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/stages,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@1d226f27
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@1d226f27
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@1d944fc0
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/stages/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@602298b + org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@602298b + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/stages/json,null} + org.eclipse.jetty.servlet.ServletHandler@602298b as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@602298b
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6=org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@602298b
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@602298b
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/stages/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-44bbb7c6
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/stages/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@1d944fc0
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@1d944fc0
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@7c3c453b
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/stages/stage,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@1fb6b8fb + org.apache.spark.ui.JettyUtils$$anon$1-3303e89e as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@1fb6b8fb + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-3303e89e as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/stages/stage,null} + org.eclipse.jetty.servlet.ServletHandler@1fb6b8fb as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@1fb6b8fb
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3303e89e}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3303e89e=org.apache.spark.ui.JettyUtils$$anon$1-3303e89e}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@1fb6b8fb
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@1fb6b8fb
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/stages/stage,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-3303e89e
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-3303e89e
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/stages/stage,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@7c3c453b
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@7c3c453b
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@1b791dca
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@149d7cc6 + org.apache.spark.ui.JettyUtils$$anon$1-cec590c as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@149d7cc6 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-cec590c as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/stages/stage/json,null} + org.eclipse.jetty.servlet.ServletHandler@149d7cc6 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@149d7cc6
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-cec590c}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-cec590c=org.apache.spark.ui.JettyUtils$$anon$1-cec590c}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@149d7cc6
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@149d7cc6
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-cec590c
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-cec590c
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/stages/stage/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@1b791dca
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@1b791dca
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@15ac02d5
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/stages/pool,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@1a10c47e + org.apache.spark.ui.JettyUtils$$anon$1-21090c88 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@1a10c47e + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-21090c88 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/stages/pool,null} + org.eclipse.jetty.servlet.ServletHandler@1a10c47e as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@1a10c47e
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-21090c88}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-21090c88=org.apache.spark.ui.JettyUtils$$anon$1-21090c88}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@1a10c47e
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@1a10c47e
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/stages/pool,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-21090c88
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-21090c88
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/stages/pool,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@15ac02d5
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@15ac02d5
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@2af9a5ef
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@d49e8c6 + org.apache.spark.ui.JettyUtils$$anon$1-d62472f as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@d49e8c6 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-d62472f as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/stages/pool/json,null} + org.eclipse.jetty.servlet.ServletHandler@d49e8c6 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@d49e8c6
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-d62472f}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-d62472f=org.apache.spark.ui.JettyUtils$$anon$1-d62472f}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@d49e8c6
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@d49e8c6
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-d62472f
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-d62472f
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/stages/pool/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@2af9a5ef
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@2af9a5ef
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@34f23816
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/storage,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2712e8f4 + org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2712e8f4 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/storage,null} + org.eclipse.jetty.servlet.ServletHandler@2712e8f4 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@2712e8f4
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70=org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@2712e8f4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@2712e8f4
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/storage,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-3ed7dd70
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/storage,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@34f23816
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@34f23816
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@6736f40f
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/storage/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@5896cb9c + org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@5896cb9c + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/storage/json,null} + org.eclipse.jetty.servlet.ServletHandler@5896cb9c as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@5896cb9c
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0=org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@5896cb9c
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@5896cb9c
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/storage/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-6f3b13d0
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/storage/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@6736f40f
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@6736f40f
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@12f9f896
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/storage/rdd,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@44b9c7c4 + org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@44b9c7c4 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/storage/rdd,null} + org.eclipse.jetty.servlet.ServletHandler@44b9c7c4 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@44b9c7c4
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd=org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@44b9c7c4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@44b9c7c4
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/storage/rdd,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-6e9a10cd
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/storage/rdd,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@12f9f896
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@12f9f896
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@7548e1fb
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@674184d + org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@674184d + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/storage/rdd/json,null} + org.eclipse.jetty.servlet.ServletHandler@674184d as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@674184d
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33=org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@674184d
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@674184d
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-6ea66c33
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/storage/rdd/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@7548e1fb
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@7548e1fb
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@505f45cc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/environment,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@3611153f + org.apache.spark.ui.JettyUtils$$anon$1-a826ff8 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@3611153f + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-a826ff8 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/environment,null} + org.eclipse.jetty.servlet.ServletHandler@3611153f as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@3611153f
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-a826ff8}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-a826ff8=org.apache.spark.ui.JettyUtils$$anon$1-a826ff8}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@3611153f
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@3611153f
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/environment,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-a826ff8
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-a826ff8
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/environment,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@505f45cc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@505f45cc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@994544
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/environment/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@5835e24a + org.apache.spark.ui.JettyUtils$$anon$1-71f0806b as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@5835e24a + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-71f0806b as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/environment/json,null} + org.eclipse.jetty.servlet.ServletHandler@5835e24a as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@5835e24a
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-71f0806b}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-71f0806b=org.apache.spark.ui.JettyUtils$$anon$1-71f0806b}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@5835e24a
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@5835e24a
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/environment/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-71f0806b
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-71f0806b
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/environment/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@994544
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@994544
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@5df92089
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/executors,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@5238896f + org.apache.spark.ui.JettyUtils$$anon$1-79ad1774 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@5238896f + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-79ad1774 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/executors,null} + org.eclipse.jetty.servlet.ServletHandler@5238896f as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@5238896f
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-79ad1774}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-79ad1774=org.apache.spark.ui.JettyUtils$$anon$1-79ad1774}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@5238896f
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@5238896f
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/executors,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-79ad1774
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-79ad1774
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/executors,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@5df92089
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@5df92089
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@6f0c45f4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/executors/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@74a85515 + org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@74a85515 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/executors/json,null} + org.eclipse.jetty.servlet.ServletHandler@74a85515 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@74a85515
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6=org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@74a85515
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@74a85515
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/executors/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-64f3ca6
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/executors/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@6f0c45f4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@6f0c45f4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@45571cfc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@4a2e1e52 + org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@4a2e1e52 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/executors/threadDump,null} + org.eclipse.jetty.servlet.ServletHandler@4a2e1e52 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@4a2e1e52
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3=org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@4a2e1e52
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@4a2e1e52
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-721fc2e3
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/executors/threadDump,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@45571cfc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@45571cfc
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@faec277
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@3dfe92ef + org.apache.spark.ui.JettyUtils$$anon$1-63187d63 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@3dfe92ef + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-63187d63 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/executors/threadDump/json,null} + org.eclipse.jetty.servlet.ServletHandler@3dfe92ef as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@3dfe92ef
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-63187d63}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-63187d63=org.apache.spark.ui.JettyUtils$$anon$1-63187d63}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@3dfe92ef
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@3dfe92ef
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-63187d63
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-63187d63
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/executors/threadDump/json,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@faec277
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@faec277
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@1b475663
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/static,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2b9b17ce + org.eclipse.jetty.servlet.DefaultServlet-7996d0d4 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2b9b17ce + [/]=>org.eclipse.jetty.servlet.DefaultServlet-7996d0d4 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/static,null} + org.eclipse.jetty.servlet.ServletHandler@2b9b17ce as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@2b9b17ce
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.eclipse.jetty.servlet.DefaultServlet-7996d0d4}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.eclipse.jetty.servlet.DefaultServlet-7996d0d4=org.eclipse.jetty.servlet.DefaultServlet-7996d0d4}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@2b9b17ce
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@2b9b17ce
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/static,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.DefaultServlet-7996d0d4
2015-09-25 18:46:37 DEBUG DefaultServlet:298 - resource base = jar:file:/home/aparna/Downloads/spark-1.5.0/assembly/target/scala-2.10/spark-assembly-1.5.0-hadoop2.2.0.jar!/org/apache/spark/ui/static
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.DefaultServlet-7996d0d4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/static,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@1b475663
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@1b475663
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@1669931a
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@1d2def55 + org.apache.spark.ui.JettyUtils$$anon$2-4243341e as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@1d2def55 + [/]=>org.apache.spark.ui.JettyUtils$$anon$2-4243341e as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/,null} + org.eclipse.jetty.servlet.ServletHandler@1d2def55 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@1d2def55
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-4243341e}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-4243341e=org.apache.spark.ui.JettyUtils$$anon$2-4243341e}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@1d2def55
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@1d2def55
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$2-4243341e
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$2-4243341e
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@1669931a
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@1669931a
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@6b24ddd7
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/api,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@274bae2c + com.sun.jersey.spi.container.servlet.ServletContainer-3b021664 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@274bae2c + [/*]=>com.sun.jersey.spi.container.servlet.ServletContainer-3b021664 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/api,null} + org.eclipse.jetty.servlet.ServletHandler@274bae2c as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@274bae2c
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/*=com.sun.jersey.spi.container.servlet.ServletContainer-3b021664}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={com.sun.jersey.spi.container.servlet.ServletContainer-3b021664=com.sun.jersey.spi.container.servlet.ServletContainer-3b021664}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@274bae2c
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@274bae2c
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/api,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting com.sun.jersey.spi.container.servlet.ServletContainer-3b021664
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED com.sun.jersey.spi.container.servlet.ServletContainer-3b021664
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/api,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@6b24ddd7
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@6b24ddd7
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.GzipHandler@12e007be
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@6eeb29c0 + org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@6eeb29c0 + [/]=>org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/stages/stage/kill,null} + org.eclipse.jetty.servlet.ServletHandler@6eeb29c0 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@6eeb29c0
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22=org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@6eeb29c0
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@6eeb29c0
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$2-16ea0f22
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/stages/stage/kill,null}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.GzipHandler@12e007be
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.GzipHandler@12e007be
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.Server@26ffd2c0
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting qtp220774932{8<=0<=0/254,-1}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED qtp220774932{8<=7<=8/254,0}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.handler.ErrorHandler@1d3d76b4
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.server.handler.ErrorHandler@1d3d76b4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.handler.ErrorHandler@1d3d76b4
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting SelectChannelConnector@0.0.0.0:4040
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting null/null
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED PooledBuffers [0/1024@6144,0/1024@16384,0/1024@-]/PooledBuffers [0/1024@6144,0/1024@32768,0/1024@-]
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.server.nio.SelectChannelConnector$ConnectorSelectorManager@6f986501
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.nio.SelectChannelConnector$ConnectorSelectorManager@6f986501
2015-09-25 18:46:37 DEBUG nio:285 - Starting Thread[qtp220774932-50 Selector0,5,main] on org.eclipse.jetty.io.nio.SelectorManager$1@2671775
2015-09-25 18:46:37 INFO  AbstractConnector:338 - Started SelectChannelConnector@0.0.0.0:4040
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED SelectChannelConnector@0.0.0.0:4040
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.server.Server@26ffd2c0
2015-09-25 18:46:37 INFO  Utils:59 - Successfully started service 'SparkUI' on port 4040.
2015-09-25 18:46:37 INFO  SparkUI:59 - Started SparkUI at http://192.168.0.18:4040
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$a]
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (7.690057 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$a]
2015-09-25 18:46:37 WARN  MetricsSystem:71 - Using default name DAGScheduler for source because spark.app.id is not set.
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(TaskSchedulerIsSet,true) from Actor[akka://sparkDriver/temp/$b]
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(TaskSchedulerIsSet,true)
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.52952 ms) AkkaMessage(TaskSchedulerIsSet,true) from Actor[akka://sparkDriver/temp/$b]
2015-09-25 18:46:37 INFO  Executor:59 - Starting executor ID driver on host localhost
2015-09-25 18:46:37 INFO  Executor:59 - Using REPL class URI: http://192.168.0.18:42168
2015-09-25 18:46:37 DEBUG InternalLoggerFactory:71 - Using SLF4J as the default logging framework
2015-09-25 18:46:37 DEBUG PlatformDependent0:76 - java.nio.Buffer.address: available
2015-09-25 18:46:37 DEBUG PlatformDependent0:76 - sun.misc.Unsafe.theUnsafe: available
2015-09-25 18:46:37 DEBUG PlatformDependent0:71 - sun.misc.Unsafe.copyMemory: available
2015-09-25 18:46:37 DEBUG PlatformDependent0:76 - java.nio.Bits.unaligned: true
2015-09-25 18:46:37 DEBUG PlatformDependent:76 - Java version: 8
2015-09-25 18:46:37 DEBUG PlatformDependent:76 - -Dio.netty.noUnsafe: false
2015-09-25 18:46:37 DEBUG PlatformDependent:76 - sun.misc.Unsafe: available
2015-09-25 18:46:37 DEBUG PlatformDependent:76 - -Dio.netty.noJavassist: false
2015-09-25 18:46:37 DEBUG PlatformDependent:71 - Javassist: unavailable
2015-09-25 18:46:37 DEBUG PlatformDependent:71 - You don't have Javassist in your class path or you don't have enough permission to load dynamically generated classes.  Please check the configuration for better performance.
2015-09-25 18:46:37 DEBUG PlatformDependent:76 - -Dio.netty.tmpdir: /tmp (java.io.tmpdir)
2015-09-25 18:46:37 DEBUG PlatformDependent:76 - -Dio.netty.bitMode: 64 (sun.arch.data.model)
2015-09-25 18:46:37 DEBUG PlatformDependent:76 - -Dio.netty.noPreferDirect: false
2015-09-25 18:46:37 DEBUG MultithreadEventLoopGroup:76 - -Dio.netty.eventLoopThreads: 8
2015-09-25 18:46:37 DEBUG NioEventLoop:76 - -Dio.netty.noKeySetOptimization: false
2015-09-25 18:46:37 DEBUG NioEventLoop:76 - -Dio.netty.selectorAutoRebuildThreshold: 512
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.numHeapArenas: 8
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.numDirectArenas: 8
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.pageSize: 8192
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.maxOrder: 11
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.chunkSize: 16777216
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.tinyCacheSize: 512
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.smallCacheSize: 256
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.normalCacheSize: 64
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.maxCachedBufferCapacity: 32768
2015-09-25 18:46:37 DEBUG PooledByteBufAllocator:76 - -Dio.netty.allocator.cacheTrimInterval: 8192
2015-09-25 18:46:37 DEBUG ThreadLocalRandom:71 - -Dio.netty.initialSeedUniquifier: 0x11782a7d38cf5e90 (took 0 ms)
2015-09-25 18:46:37 DEBUG ByteBufUtil:76 - -Dio.netty.allocator.type: unpooled
2015-09-25 18:46:37 DEBUG ByteBufUtil:76 - -Dio.netty.threadLocalDirectBufferSize: 65536
2015-09-25 18:46:37 DEBUG NetUtil:86 - Loopback interface: lo (lo, 0:0:0:0:0:0:0:1%lo)
2015-09-25 18:46:37 DEBUG NetUtil:81 - /proc/sys/net/core/somaxconn: 128
2015-09-25 18:46:37 DEBUG TransportServer:127 - Shuffle server started on port :53087
2015-09-25 18:46:37 INFO  Utils:59 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 53087.
2015-09-25 18:46:37 INFO  NettyBlockTransferService:59 - Server created on 53087
2015-09-25 18:46:37 INFO  BlockManagerMaster:59 - Trying to register BlockManager
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(RegisterBlockManager(BlockManagerId(driver, localhost, 53087),555755765,AkkaRpcEndpointRef(Actor[akka://sparkDriver/user/BlockManagerEndpoint1#-1116073445])),true) from Actor[akka://sparkDriver/temp/$c]
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(RegisterBlockManager(BlockManagerId(driver, localhost, 53087),555755765,AkkaRpcEndpointRef(Actor[akka://sparkDriver/user/BlockManagerEndpoint1#-1116073445])),true)
2015-09-25 18:46:37 INFO  BlockManagerMasterEndpoint:59 - Registering block manager localhost:53087 with 530.0 MB RAM, BlockManagerId(driver, localhost, 53087)
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (3.574621 ms) AkkaMessage(RegisterBlockManager(BlockManagerId(driver, localhost, 53087),555755765,AkkaRpcEndpointRef(Actor[akka://sparkDriver/user/BlockManagerEndpoint1#-1116073445])),true) from Actor[akka://sparkDriver/temp/$c]
2015-09-25 18:46:37 INFO  BlockManagerMaster:59 - Registered BlockManager
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9=org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + o.e.j.s.ServletContextHandler{/metrics/json,null} as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/metrics/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@280d5a82 + org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@280d5a82 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/metrics/json,null} + org.eclipse.jetty.servlet.ServletHandler@280d5a82 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@280d5a82
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9=org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@280d5a82
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@280d5a82
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/metrics/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-1958c0d9
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/metrics/json,null}
2015-09-25 18:46:37 INFO  SparkILoop:59 - Created spark context..
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExecutorRegistered(driver),true) from Actor[akka://sparkDriver/temp/$d]
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExecutorRegistered(driver),true)
2015-09-25 18:46:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.529307 ms) AkkaMessage(ExecutorRegistered(driver),true) from Actor[akka://sparkDriver/temp/$d]
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-54941dfd}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-54941dfd=org.apache.spark.ui.JettyUtils$$anon$1-54941dfd}
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-5a7e81}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5a7e81=org.apache.spark.ui.JettyUtils$$anon$1-5a7e81}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + o.e.j.s.ServletContextHandler{/SQL,null} as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/SQL,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2152fde5 + org.apache.spark.ui.JettyUtils$$anon$1-54941dfd as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2152fde5 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-54941dfd as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/SQL,null} + org.eclipse.jetty.servlet.ServletHandler@2152fde5 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@2152fde5
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-54941dfd}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-54941dfd=org.apache.spark.ui.JettyUtils$$anon$1-54941dfd}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@2152fde5
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@2152fde5
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/SQL,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-54941dfd
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-54941dfd
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/SQL,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + o.e.j.s.ServletContextHandler{/SQL/json,null} as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/SQL/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@459d2ee6 + org.apache.spark.ui.JettyUtils$$anon$1-5a7e81 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@459d2ee6 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-5a7e81 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/SQL/json,null} + org.eclipse.jetty.servlet.ServletHandler@459d2ee6 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@459d2ee6
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-5a7e81}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-5a7e81=org.apache.spark.ui.JettyUtils$$anon$1-5a7e81}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@459d2ee6
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@459d2ee6
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/SQL/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-5a7e81
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-5a7e81
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/SQL/json,null}
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-60e47aab}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-60e47aab=org.apache.spark.ui.JettyUtils$$anon$1-60e47aab}
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-261a66b8}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-261a66b8=org.apache.spark.ui.JettyUtils$$anon$1-261a66b8}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + o.e.j.s.ServletContextHandler{/SQL/execution,null} as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/SQL/execution,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@111fe921 + org.apache.spark.ui.JettyUtils$$anon$1-60e47aab as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@111fe921 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-60e47aab as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/SQL/execution,null} + org.eclipse.jetty.servlet.ServletHandler@111fe921 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@111fe921
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-60e47aab}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-60e47aab=org.apache.spark.ui.JettyUtils$$anon$1-60e47aab}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@111fe921
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@111fe921
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/SQL/execution,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-60e47aab
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-60e47aab
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/SQL/execution,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + o.e.j.s.ServletContextHandler{/SQL/execution/json,null} as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/SQL/execution/json,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2db461b5 + org.apache.spark.ui.JettyUtils$$anon$1-261a66b8 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@2db461b5 + [/]=>org.apache.spark.ui.JettyUtils$$anon$1-261a66b8 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/SQL/execution/json,null} + org.eclipse.jetty.servlet.ServletHandler@2db461b5 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@2db461b5
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.apache.spark.ui.JettyUtils$$anon$1-261a66b8}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.apache.spark.ui.JettyUtils$$anon$1-261a66b8=org.apache.spark.ui.JettyUtils$$anon$1-261a66b8}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@2db461b5
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@2db461b5
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/SQL/execution/json,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.apache.spark.ui.JettyUtils$$anon$1-261a66b8
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.apache.spark.ui.JettyUtils$$anon$1-261a66b8
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/SQL/execution/json,null}
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1=org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.server.handler.ContextHandlerCollection@3335afcf + o.e.j.s.ServletContextHandler{/static/sql,null} as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting o.e.j.s.ServletContextHandler{/static/sql,null}
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@6da646b8 + org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1 as servlet
2015-09-25 18:46:37 DEBUG Container:206 - Container org.eclipse.jetty.servlet.ServletHandler@6da646b8 + [/]=>org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1 as servletMapping
2015-09-25 18:46:37 DEBUG Container:206 - Container o.e.j.s.ServletContextHandler{/static/sql,null} + org.eclipse.jetty.servlet.ServletHandler@6da646b8 as handler
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.ServletHandler@6da646b8
2015-09-25 18:46:37 DEBUG ServletHandler:1347 - filterNameMap={}
2015-09-25 18:46:37 DEBUG ServletHandler:1348 - pathFilters=null
2015-09-25 18:46:37 DEBUG ServletHandler:1349 - servletFilterMap=null
2015-09-25 18:46:37 DEBUG ServletHandler:1350 - servletPathMap={/=org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1}
2015-09-25 18:46:37 DEBUG ServletHandler:1351 - servletNameMap={org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1=org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1}
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting org.eclipse.jetty.servlet.ServletHandler@6da646b8
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.ServletHandler@6da646b8
2015-09-25 18:46:37 DEBUG AbstractHandler:57 - starting o.e.j.s.ServletContextHandler{/static/sql,null}
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:179 - starting org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1
2015-09-25 18:46:37 DEBUG DefaultServlet:298 - resource base = jar:file:/home/aparna/Downloads/spark-1.5.0/assembly/target/scala-2.10/spark-assembly-1.5.0-hadoop2.2.0.jar!/org/apache/spark/sql/execution/ui/static
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED org.eclipse.jetty.servlet.DefaultServlet-34eaf9c1
2015-09-25 18:46:37 DEBUG AbstractLifeCycle:172 - STARTED o.e.j.s.ServletContextHandler{/static/sql,null}
2015-09-25 18:46:37 INFO  SparkILoop:59 - Created sql context..
2015-09-25 18:46:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@38856698,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$e]
2015-09-25 18:46:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@38856698,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:46:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.890767 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@38856698,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$e]
2015-09-25 18:46:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$f]
2015-09-25 18:46:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:46:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (4.241843 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$f]
2015-09-25 18:47:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@78a7e8cc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$g]
2015-09-25 18:47:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@78a7e8cc,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.706853 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@78a7e8cc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$g]
2015-09-25 18:47:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$h]
2015-09-25 18:47:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.183995 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$h]
2015-09-25 18:47:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2a492ba8,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$i]
2015-09-25 18:47:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2a492ba8,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.34283 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2a492ba8,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$i]
2015-09-25 18:47:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$j]
2015-09-25 18:47:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.427637 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$j]
2015-09-25 18:47:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@52352f6d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$k]
2015-09-25 18:47:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@52352f6d,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.435774 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@52352f6d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$k]
2015-09-25 18:47:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$l]
2015-09-25 18:47:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.941113 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$l]
2015-09-25 18:47:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@27bcaf16,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$m]
2015-09-25 18:47:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@27bcaf16,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.494633 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@27bcaf16,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$m]
2015-09-25 18:47:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$n]
2015-09-25 18:47:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.899218 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$n]
2015-09-25 18:47:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$o]
2015-09-25 18:47:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:47:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.936173 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$o]
2015-09-25 18:47:43 INFO  MemoryStore:59 - ensureFreeSpace(110248) called with curMem=0, maxMem=555755765
2015-09-25 18:47:43 INFO  MemoryStore:59 - Block broadcast_0 stored as values in memory (estimated size 107.7 KB, free 529.9 MB)
2015-09-25 18:47:43 DEBUG BlockManager:63 - Put block broadcast_0 locally took  106 ms
2015-09-25 18:47:43 DEBUG BlockManager:63 - Putting block broadcast_0 without replication took  107 ms
2015-09-25 18:47:43 INFO  MemoryStore:59 - ensureFreeSpace(10065) called with curMem=110248, maxMem=555755765
2015-09-25 18:47:43 INFO  MemoryStore:59 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 9.8 KB, free 529.9 MB)
2015-09-25 18:47:43 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),10065,0,0),true) from Actor[akka://sparkDriver/temp/$p]
2015-09-25 18:47:43 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),10065,0,0),true)
2015-09-25 18:47:43 INFO  BlockManagerInfo:59 - Added broadcast_0_piece0 in memory on localhost:53087 (size: 9.8 KB, free: 530.0 MB)
2015-09-25 18:47:43 DEBUG BlockManagerMaster:63 - Updated info of block broadcast_0_piece0
2015-09-25 18:47:43 DEBUG BlockManager:63 - Told master about block broadcast_0_piece0
2015-09-25 18:47:43 DEBUG BlockManager:63 - Put block broadcast_0_piece0 locally took  3 ms
2015-09-25 18:47:43 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (2.358689 ms) AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_0_piece0,StorageLevel(false, true, false, false, 1),10065,0,0),true) from Actor[akka://sparkDriver/temp/$p]
2015-09-25 18:47:43 DEBUG BlockManager:63 - Putting block broadcast_0_piece0 without replication took  4 ms
2015-09-25 18:47:43 INFO  SparkContext:59 - Created broadcast 0 from textFile at <console>:21
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function1> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32) +++
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + declared fields: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public static final long org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.serialVersionUID
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      private final org.apache.spark.SparkContext$$anonfun$hadoopFile$1 org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.$outer
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + declared methods: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.apply(java.lang.Object)
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public final void org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.apply(org.apache.hadoop.mapred.JobConf)
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + inner classes: 0
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outer classes: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      org.apache.spark.SparkContext$$anonfun$hadoopFile$1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      org.apache.spark.SparkContext
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outer objects: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      <function0>
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      org.apache.spark.SparkContext@7b79ff1c
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      (class org.apache.spark.SparkContext$$anonfun$hadoopFile$1,Set(path$6))
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      (class org.apache.spark.SparkContext,Set())
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outermost object is not a closure, so do not clone it: (class org.apache.spark.SparkContext,org.apache.spark.SparkContext@7b79ff1c)
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + cloning the object <function0> of class org.apache.spark.SparkContext$$anonfun$hadoopFile$1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + cleaning cloned closure <function0> recursively (org.apache.spark.SparkContext$$anonfun$hadoopFile$1)
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function0> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1) +++
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + declared fields: 7
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public static final long org.apache.spark.SparkContext$$anonfun$hadoopFile$1.serialVersionUID
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      private final org.apache.spark.SparkContext org.apache.spark.SparkContext$$anonfun$hadoopFile$1.$outer
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public final java.lang.String org.apache.spark.SparkContext$$anonfun$hadoopFile$1.path$6
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.inputFormatClass$1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.keyClass$1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      private final java.lang.Class org.apache.spark.SparkContext$$anonfun$hadoopFile$1.valueClass$1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      private final int org.apache.spark.SparkContext$$anonfun$hadoopFile$1.minPartitions$3
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + declared methods: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$hadoopFile$1.apply()
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public final org.apache.spark.rdd.HadoopRDD org.apache.spark.SparkContext$$anonfun$hadoopFile$1.apply()
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + inner classes: 1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outer classes: 1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      org.apache.spark.SparkContext
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outer objects: 1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      org.apache.spark.SparkContext@7b79ff1c
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      (class org.apache.spark.SparkContext$$anonfun$hadoopFile$1,Set(path$6))
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      (class org.apache.spark.SparkContext,Set())
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outermost object is not a closure, so do not clone it: (class org.apache.spark.SparkContext,org.apache.spark.SparkContext@7b79ff1c)
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + the starting closure doesn't actually need org.apache.spark.SparkContext@7b79ff1c, so we null it out
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  +++ closure <function0> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1) is now cleaned +++
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  +++ closure <function1> (org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32) is now cleaned +++
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function1> (org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$9) +++
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + declared fields: 1
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public static final long org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$9.serialVersionUID
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + declared methods: 2
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public final java.lang.Object org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$9.apply(java.lang.Object)
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -      public final java.lang.String org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$9.apply(scala.Tuple2)
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + inner classes: 0
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outer classes: 0
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + outer objects: 0
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 0
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  + there are no enclosing objects!
2015-09-25 18:47:43 DEBUG ClosureCleaner:63 -  +++ closure <function1> (org.apache.spark.SparkContext$$anonfun$textFile$1$$anonfun$apply$9) is now cleaned +++
2015-09-25 18:47:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5836739f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$q]
2015-09-25 18:47:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5836739f,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.288013 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5836739f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$q]
2015-09-25 18:47:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$r]
2015-09-25 18:47:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.55699 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$r]
2015-09-25 18:47:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@569645bc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$s]
2015-09-25 18:47:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@569645bc,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.354936 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@569645bc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$s]
2015-09-25 18:47:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$t]
2015-09-25 18:47:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:47:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.718749 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$t]
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function1> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$2) +++
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + declared fields: 1
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -      public static final long $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$2.serialVersionUID
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + declared methods: 2
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -      public final java.lang.Object $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$2.apply(java.lang.Object)
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -      public final scala.collection.mutable.ArrayOps $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$2.apply(java.lang.String)
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + inner classes: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + outer classes: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + outer objects: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + there are no enclosing objects!
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  +++ closure <function1> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$2) is now cleaned +++
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function1> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$3) +++
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + declared fields: 1
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -      public static final long $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$3.serialVersionUID
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + declared methods: 2
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -      public final java.lang.Object $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$3.apply(java.lang.Object)
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -      public final scala.Tuple2 $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$3.apply(java.lang.String)
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + inner classes: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + outer classes: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + outer objects: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 0
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  + there are no enclosing objects!
2015-09-25 18:48:03 DEBUG ClosureCleaner:63 -  +++ closure <function1> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$3) is now cleaned +++
2015-09-25 18:48:03 DEBUG BlockManager:63 - Getting local block broadcast_0
2015-09-25 18:48:03 DEBUG BlockManager:63 - Level for block broadcast_0 is StorageLevel(true, true, false, true, 1)
2015-09-25 18:48:03 DEBUG BlockManager:63 - Getting block broadcast_0 from memory
2015-09-25 18:48:03 DEBUG HadoopRDD:84 - SplitLocationInfo and other new Hadoop classes are unavailable. Using the older Hadoop location info code.
java.lang.ClassNotFoundException: org.apache.hadoop.mapred.InputSplitWithLocationInfo
	at scala.tools.nsc.interpreter.AbstractFileClassLoader.findClass(AbstractFileClassLoader.scala:83)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:424)
	at java.lang.ClassLoader.loadClass(ClassLoader.java:357)
	at java.lang.Class.forName0(Native Method)
	at java.lang.Class.forName(Class.java:348)
	at org.apache.spark.util.Utils$.classForName(Utils.scala:173)
	at org.apache.spark.rdd.HadoopRDD$SplitInfoReflections.<init>(HadoopRDD.scala:386)
	at org.apache.spark.rdd.HadoopRDD$.liftedTree1$1(HadoopRDD.scala:396)
	at org.apache.spark.rdd.HadoopRDD$.<init>(HadoopRDD.scala:395)
	at org.apache.spark.rdd.HadoopRDD$.<clinit>(HadoopRDD.scala)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:165)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:290)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:290)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:306)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:289)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:23)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:28)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:30)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:32)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:34)
	at $line19.$read$$iwC$$iwC$$iwC.<init>(<console>:36)
	at $line19.$read$$iwC$$iwC.<init>(<console>:38)
	at $line19.$read$$iwC.<init>(<console>:40)
	at $line19.$read.<init>(<console>:42)
	at $line19.$read$.<init>(<console>:46)
	at $line19.$read$.<clinit>(<console>)
	at $line19.$eval$.<init>(<console>:7)
	at $line19.$eval$.<clinit>(<console>)
	at $line19.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-09-25 18:48:03 DEBUG HadoopRDD:63 - Creating new JobConf and caching it for later re-use
2015-09-25 18:48:03 DEBUG Shell:243 - Failed to detect a valid hadoop home directory
java.io.IOException: HADOOP_HOME or hadoop.home.dir are not set.
	at org.apache.hadoop.util.Shell.checkHadoopHome(Shell.java:225)
	at org.apache.hadoop.util.Shell.<clinit>(Shell.java:250)
	at org.apache.hadoop.util.StringUtils.<clinit>(StringUtils.java:76)
	at org.apache.hadoop.mapred.FileInputFormat.setInputPaths(FileInputFormat.java:362)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.apply(SparkContext.scala:1007)
	at org.apache.spark.SparkContext$$anonfun$hadoopFile$1$$anonfun$32.apply(SparkContext.scala:1007)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD$$anonfun$getJobConf$6.apply(HadoopRDD.scala:176)
	at scala.Option.map(Option.scala:145)
	at org.apache.spark.rdd.HadoopRDD.getJobConf(HadoopRDD.scala:176)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:200)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:239)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:237)
	at scala.Option.getOrElse(Option.scala:120)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:237)
	at org.apache.spark.Partitioner$.defaultPartitioner(Partitioner.scala:65)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:290)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$3.apply(PairRDDFunctions.scala:290)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:147)
	at org.apache.spark.rdd.RDDOperationScope$.withScope(RDDOperationScope.scala:108)
	at org.apache.spark.rdd.RDD.withScope(RDD.scala:306)
	at org.apache.spark.rdd.PairRDDFunctions.reduceByKey(PairRDDFunctions.scala:289)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:23)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:28)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:30)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:32)
	at $line19.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:34)
	at $line19.$read$$iwC$$iwC$$iwC.<init>(<console>:36)
	at $line19.$read$$iwC$$iwC.<init>(<console>:38)
	at $line19.$read$$iwC.<init>(<console>:40)
	at $line19.$read.<init>(<console>:42)
	at $line19.$read$.<init>(<console>:46)
	at $line19.$read$.<clinit>(<console>)
	at $line19.$eval$.<init>(<console>:7)
	at $line19.$eval$.<clinit>(<console>)
	at $line19.$eval.$print(<console>)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)
	at org.apache.spark.repl.SparkIMain$Request.loadAndRun(SparkIMain.scala:1340)
	at org.apache.spark.repl.SparkIMain.loadAndRunReq$1(SparkIMain.scala:840)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:871)
	at org.apache.spark.repl.SparkIMain.interpret(SparkIMain.scala:819)
	at org.apache.spark.repl.SparkILoop.reallyInterpret$1(SparkILoop.scala:857)
	at org.apache.spark.repl.SparkILoop.interpretStartingWith(SparkILoop.scala:902)
	at org.apache.spark.repl.SparkILoop.command(SparkILoop.scala:814)
	at org.apache.spark.repl.SparkILoop.processLine$1(SparkILoop.scala:657)
	at org.apache.spark.repl.SparkILoop.innerLoop$1(SparkILoop.scala:665)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$loop(SparkILoop.scala:670)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply$mcZ$sp(SparkILoop.scala:997)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop$$anonfun$org$apache$spark$repl$SparkILoop$$process$1.apply(SparkILoop.scala:945)
	at scala.tools.nsc.util.ScalaClassLoader$.savingContextLoader(ScalaClassLoader.scala:135)
	at org.apache.spark.repl.SparkILoop.org$apache$spark$repl$SparkILoop$$process(SparkILoop.scala:945)
	at org.apache.spark.repl.SparkILoop.process(SparkILoop.scala:1059)
	at org.apache.spark.repl.Main$.main(Main.scala:31)
	at org.apache.spark.repl.Main.main(Main.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:497)
	at org.apache.spark.deploy.SparkSubmit$.org$apache$spark$deploy$SparkSubmit$$runMain(SparkSubmit.scala:672)
	at org.apache.spark.deploy.SparkSubmit$.doRunMain$1(SparkSubmit.scala:180)
	at org.apache.spark.deploy.SparkSubmit$.submit(SparkSubmit.scala:205)
	at org.apache.spark.deploy.SparkSubmit$.main(SparkSubmit.scala:120)
	at org.apache.spark.deploy.SparkSubmit.main(SparkSubmit.scala)
2015-09-25 18:48:03 DEBUG Shell:326 - setsid exited with exit code 0
2015-09-25 18:48:03 DEBUG :116 - address: aparna-Inspiron-5548/127.0.1.1 isLoopbackAddress: true, with host 127.0.1.1 aparna-Inspiron-5548
2015-09-25 18:48:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2ec61c4d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$u]
2015-09-25 18:48:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2ec61c4d,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.738436 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2ec61c4d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$u]
2015-09-25 18:48:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$v]
2015-09-25 18:48:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.952019 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$v]
2015-09-25 18:48:08 INFO  FileInputFormat:253 - Total input paths to process : 1
2015-09-25 18:48:08 DEBUG FileInputFormat:328 - Total # of splits: 2
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$14) +++
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + declared fields: 1
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$14.serialVersionUID
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + declared methods: 1
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$14.apply(java.lang.Object)
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + inner classes: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + outer classes: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + outer objects: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + there are no enclosing objects!
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  +++ closure <function1> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$reduceByKey$1$$anonfun$apply$14) is now cleaned +++
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function2> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1) +++
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + declared fields: 1
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public static final long $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.serialVersionUID
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + declared methods: 3
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public int $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply$mcIII$sp(int,int)
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public final int $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(int,int)
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public final java.lang.Object $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(java.lang.Object,java.lang.Object)
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + inner classes: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + outer classes: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + outer objects: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + there are no enclosing objects!
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  +++ closure <function2> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1) is now cleaned +++
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function2> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1) +++
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + declared fields: 1
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public static final long $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.serialVersionUID
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + declared methods: 3
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public int $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply$mcIII$sp(int,int)
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public final int $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(int,int)
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -      public final java.lang.Object $line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1.apply(java.lang.Object,java.lang.Object)
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + inner classes: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + outer classes: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + outer objects: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 0
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  + there are no enclosing objects!
2015-09-25 18:48:08 DEBUG ClosureCleaner:63 -  +++ closure <function2> ($line19.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$anonfun$1) is now cleaned +++
2015-09-25 18:48:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@313fe63d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$w]
2015-09-25 18:48:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@313fe63d,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.642589 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@313fe63d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$w]
2015-09-25 18:48:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$x]
2015-09-25 18:48:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.942366 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$x]
2015-09-25 18:48:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7a75dea2,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$y]
2015-09-25 18:48:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7a75dea2,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.665041 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7a75dea2,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$y]
2015-09-25 18:48:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$z]
2015-09-25 18:48:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.788762 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$z]
2015-09-25 18:48:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@1902be2f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$A]
2015-09-25 18:48:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@1902be2f,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.010705 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@1902be2f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$A]
2015-09-25 18:48:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$B]
2015-09-25 18:48:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.122427 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$B]
2015-09-25 18:48:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$C]
2015-09-25 18:48:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:48:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.827035 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$C]
2015-09-25 18:48:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@62b7a425,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$D]
2015-09-25 18:48:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@62b7a425,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.05869 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@62b7a425,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$D]
2015-09-25 18:48:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$E]
2015-09-25 18:48:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.77505 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$E]
2015-09-25 18:48:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@20b1737a,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$F]
2015-09-25 18:48:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@20b1737a,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.544112 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@20b1737a,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$F]
2015-09-25 18:48:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$G]
2015-09-25 18:48:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:48:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.387484 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$G]
2015-09-25 18:49:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5afec10e,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$H]
2015-09-25 18:49:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5afec10e,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.752764 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5afec10e,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$H]
2015-09-25 18:49:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$I]
2015-09-25 18:49:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.069456 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$I]
2015-09-25 18:49:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@74652900,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$J]
2015-09-25 18:49:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@74652900,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.352658 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@74652900,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$J]
2015-09-25 18:49:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$K]
2015-09-25 18:49:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.337418 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$K]
2015-09-25 18:49:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@781a0265,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$L]
2015-09-25 18:49:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@781a0265,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.309003 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@781a0265,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$L]
2015-09-25 18:49:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$M]
2015-09-25 18:49:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.481086 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$M]
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function1> (org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30) +++
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + declared fields: 1
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public static final long org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30.serialVersionUID
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + declared methods: 2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public final java.lang.Object org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30.apply(java.lang.Object)
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public final scala.collection.Iterator org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30.apply(scala.collection.Iterator)
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + inner classes: 1
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30$$anonfun$apply$49
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outer classes: 0
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outer objects: 0
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 0
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + there are no enclosing objects!
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  +++ closure <function1> (org.apache.spark.rdd.RDD$$anonfun$saveAsTextFile$1$$anonfun$30) is now cleaned +++
2015-09-25 18:49:29 DEBUG PairRDDFunctions:63 - Saving as hadoop file of type (NullWritable, Text)
2015-09-25 18:49:29 INFO  deprecation:840 - mapred.tip.id is deprecated. Instead, use mapreduce.task.id
2015-09-25 18:49:29 INFO  deprecation:840 - mapred.task.id is deprecated. Instead, use mapreduce.task.attempt.id
2015-09-25 18:49:29 INFO  deprecation:840 - mapred.task.is.map is deprecated. Instead, use mapreduce.task.ismap
2015-09-25 18:49:29 INFO  deprecation:840 - mapred.task.partition is deprecated. Instead, use mapreduce.task.partition
2015-09-25 18:49:29 INFO  deprecation:840 - mapred.job.id is deprecated. Instead, use mapreduce.job.id
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function2> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13) +++
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + declared fields: 4
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.serialVersionUID
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      private final org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1 org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.$outer
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      private final org.apache.spark.util.SerializableConfiguration org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.wrappedConf$2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public final org.apache.spark.SparkHadoopWriter org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.writer$2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + declared methods: 3
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1 org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.org$apache$spark$rdd$PairRDDFunctions$$anonfun$$anonfun$$$outer()
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public final void org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(org.apache.spark.TaskContext,scala.collection.Iterator)
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(java.lang.Object,java.lang.Object)
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + inner classes: 3
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$56
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outer classes: 2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outer objects: 2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      <function0>
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions@2c914aa3
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + populating accessed fields because this is the starting closure
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      (class org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1,Set($outer))
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      (class org.apache.spark.rdd.PairRDDFunctions,Set())
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outermost object is not a closure, so do not clone it: (class org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.PairRDDFunctions@2c914aa3)
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + cloning the object <function0> of class org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + cleaning cloned closure <function0> recursively (org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1)
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 - +++ Cleaning closure <function0> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1) +++
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + declared fields: 3
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public static final long org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.serialVersionUID
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      private final org.apache.spark.rdd.PairRDDFunctions org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.$outer
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      private final org.apache.hadoop.mapred.JobConf org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.conf$4
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + declared methods: 4
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public void org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply$mcV$sp()
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public org.apache.spark.rdd.PairRDDFunctions org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.org$apache$spark$rdd$PairRDDFunctions$$anonfun$$$outer()
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public final java.lang.Object org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply()
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      public final void org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1.apply()
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + inner classes: 5
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$56
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$6
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13$$anonfun$apply$7
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$apply$mcV$sp$2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outer classes: 1
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outer objects: 1
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      org.apache.spark.rdd.PairRDDFunctions@2c914aa3
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + fields accessed by starting closure: 2
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      (class org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1,Set($outer))
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -      (class org.apache.spark.rdd.PairRDDFunctions,Set())
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  + outermost object is not a closure, so do not clone it: (class org.apache.spark.rdd.PairRDDFunctions,org.apache.spark.rdd.PairRDDFunctions@2c914aa3)
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  +++ closure <function0> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1) is now cleaned +++
2015-09-25 18:49:29 DEBUG ClosureCleaner:63 -  +++ closure <function2> (org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13) is now cleaned +++
2015-09-25 18:49:29 INFO  SparkContext:59 - Starting job: saveAsTextFile at <console>:26
2015-09-25 18:49:29 INFO  DAGScheduler:59 - Registering RDD 3 (map at <console>:23)
2015-09-25 18:49:29 INFO  DAGScheduler:59 - Got job 0 (saveAsTextFile at <console>:26) with 2 output partitions
2015-09-25 18:49:29 INFO  DAGScheduler:59 - Final stage: ResultStage 1(saveAsTextFile at <console>:26)
2015-09-25 18:49:29 INFO  DAGScheduler:59 - Parents of final stage: List(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3ea1d448),true) from Actor[akka://sparkDriver/temp/$N]
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3ea1d448),true)
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.067565 ms) AkkaMessage(GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@3ea1d448),true) from Actor[akka://sparkDriver/temp/$N]
2015-09-25 18:49:29 INFO  DAGScheduler:59 - Missing parents: List(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ResultStage 1)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - missing: List(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - missing: List()
2015-09-25 18:49:29 INFO  DAGScheduler:59 - Submitting ShuffleMapStage 0 (MapPartitionsRDD[3] at map at <console>:23), which has no missing parents
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitMissingTasks(ShuffleMapStage 0)
2015-09-25 18:49:29 INFO  MemoryStore:59 - ensureFreeSpace(4168) called with curMem=120313, maxMem=555755765
2015-09-25 18:49:29 INFO  MemoryStore:59 - Block broadcast_1 stored as values in memory (estimated size 4.1 KB, free 529.9 MB)
2015-09-25 18:49:29 DEBUG BlockManager:63 - Put block broadcast_1 locally took  2 ms
2015-09-25 18:49:29 DEBUG BlockManager:63 - Putting block broadcast_1 without replication took  2 ms
2015-09-25 18:49:29 INFO  MemoryStore:59 - ensureFreeSpace(2312) called with curMem=124481, maxMem=555755765
2015-09-25 18:49:29 INFO  MemoryStore:59 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2.3 KB, free 529.9 MB)
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),2312,0,0),true) from Actor[akka://sparkDriver/temp/$O]
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),2312,0,0),true)
2015-09-25 18:49:29 INFO  BlockManagerInfo:59 - Added broadcast_1_piece0 in memory on localhost:53087 (size: 2.3 KB, free: 530.0 MB)
2015-09-25 18:49:29 DEBUG BlockManagerMaster:63 - Updated info of block broadcast_1_piece0
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.891422 ms) AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_1_piece0,StorageLevel(false, true, false, false, 1),2312,0,0),true) from Actor[akka://sparkDriver/temp/$O]
2015-09-25 18:49:29 DEBUG BlockManager:63 - Told master about block broadcast_1_piece0
2015-09-25 18:49:29 DEBUG BlockManager:63 - Put block broadcast_1_piece0 locally took  3 ms
2015-09-25 18:49:29 DEBUG BlockManager:63 - Putting block broadcast_1_piece0 without replication took  3 ms
2015-09-25 18:49:29 INFO  SparkContext:59 - Created broadcast 1 from broadcast at DAGScheduler.scala:861
2015-09-25 18:49:29 INFO  DAGScheduler:59 - Submitting 2 missing tasks from ShuffleMapStage 0 (MapPartitionsRDD[3] at map at <console>:23)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - New pending tasks: Set(ShuffleMapTask(0, 1), ShuffleMapTask(0, 0))
2015-09-25 18:49:29 INFO  TaskSchedulerImpl:59 - Adding task set 0.0 with 2 tasks
2015-09-25 18:49:29 DEBUG TaskSetManager:63 - Epoch for TaskSet 0.0: 0
2015-09-25 18:49:29 DEBUG TaskSetManager:63 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ReviveOffers,false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ReviveOffers,false)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ResultStage 1)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - missing: List(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ResultStage 1)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - missing: List(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG TaskSchedulerImpl:63 - parentName: , name: TaskSet_0, runningTasks: 0
2015-09-25 18:49:29 DEBUG TaskSetManager:63 - Valid locality levels for TaskSet 0.0: NO_PREF, ANY
2015-09-25 18:49:29 INFO  TaskSetManager:59 - Starting task 0.0 in stage 0.0 (TID 0, localhost, PROCESS_LOCAL, 2143 bytes)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ResultStage 1)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - missing: List(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ShuffleMapStage 0)
2015-09-25 18:49:29 INFO  TaskSetManager:59 - Starting task 1.0 in stage 0.0 (TID 1, localhost, PROCESS_LOCAL, 2143 bytes)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ResultStage 1)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - missing: List(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG DAGScheduler:63 - submitStage(ShuffleMapStage 0)
2015-09-25 18:49:29 DEBUG TaskSetManager:63 - No tasks for locality level NO_PREF, so moving to locality level ANY
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (39.164746 ms) AkkaMessage(ReviveOffers,false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:29 INFO  Executor:59 - Running task 0.0 in stage 0.0 (TID 0)
2015-09-25 18:49:29 INFO  Executor:59 - Running task 1.0 in stage 0.0 (TID 1)
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false)
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.359714 ms) AkkaMessage(StatusUpdate(0,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(1,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(1,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false)
2015-09-25 18:49:29 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.148914 ms) AkkaMessage(StatusUpdate(1,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:29 DEBUG Executor:63 - Task 0's epoch is 0
2015-09-25 18:49:29 DEBUG Executor:63 - Task 1's epoch is 0
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting local block broadcast_1
2015-09-25 18:49:29 DEBUG BlockManager:63 - Level for block broadcast_1 is StorageLevel(true, true, false, true, 1)
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting block broadcast_1 from memory
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting local block broadcast_1
2015-09-25 18:49:29 DEBUG BlockManager:63 - Level for block broadcast_1 is StorageLevel(true, true, false, true, 1)
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting block broadcast_1 from memory
2015-09-25 18:49:29 INFO  HadoopRDD:59 - Input split: file:/home/aparna/Downloads/RonaldoTweets.txt:7184820+7184820
2015-09-25 18:49:29 INFO  HadoopRDD:59 - Input split: file:/home/aparna/Downloads/RonaldoTweets.txt:0+7184820
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting local block broadcast_0
2015-09-25 18:49:29 DEBUG BlockManager:63 - Level for block broadcast_0 is StorageLevel(true, true, false, true, 1)
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting block broadcast_0 from memory
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting local block broadcast_0
2015-09-25 18:49:29 DEBUG BlockManager:63 - Level for block broadcast_0 is StorageLevel(true, true, false, true, 1)
2015-09-25 18:49:29 DEBUG HadoopRDD:63 - Re-using cached JobConf
2015-09-25 18:49:29 DEBUG BlockManager:63 - Getting block broadcast_0 from memory
2015-09-25 18:49:29 DEBUG HadoopRDD:63 - Re-using cached JobConf
2015-09-25 18:49:29 DEBUG SparkHadoopUtil:84 - Couldn't find method for retrieving thread-level FileSystem input data
java.lang.NoSuchMethodException: org.apache.hadoop.fs.FileSystem$Statistics.getThreadStatistics()
	at java.lang.Class.getDeclaredMethod(Class.java:2130)
	at org.apache.spark.util.Utils$.invoke(Utils.scala:1991)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.deploy.SparkHadoopUtil.getFileSystemThreadStatistics(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil.getFSBytesReadOnThreadCallback(SparkHadoopUtil.scala:142)
	at org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$2.apply(HadoopRDD.scala:229)
	at org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$2.apply(HadoopRDD.scala:227)
	at scala.Option.orElse(Option.scala:257)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:226)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:216)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-09-25 18:49:29 DEBUG SparkHadoopUtil:84 - Couldn't find method for retrieving thread-level FileSystem input data
java.lang.NoSuchMethodException: org.apache.hadoop.fs.FileSystem$Statistics.getThreadStatistics()
	at java.lang.Class.getDeclaredMethod(Class.java:2130)
	at org.apache.spark.util.Utils$.invoke(Utils.scala:1991)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.deploy.SparkHadoopUtil.getFileSystemThreadStatistics(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil.getFSBytesReadOnThreadCallback(SparkHadoopUtil.scala:142)
	at org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$2.apply(HadoopRDD.scala:229)
	at org.apache.spark.rdd.HadoopRDD$$anon$1$$anonfun$2.apply(HadoopRDD.scala:227)
	at scala.Option.orElse(Option.scala:257)
	at org.apache.spark.rdd.HadoopRDD$$anon$1.<init>(HadoopRDD.scala:226)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:216)
	at org.apache.spark.rdd.HadoopRDD.compute(HadoopRDD.scala:101)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:38)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:297)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:264)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:73)
	at org.apache.spark.scheduler.ShuffleMapTask.runTask(ShuffleMapTask.scala:41)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-09-25 18:49:31 INFO  Executor:59 - Finished task 0.0 in stage 0.0 (TID 0). 2254 bytes result sent to driver
2015-09-25 18:49:31 INFO  Executor:59 - Finished task 1.0 in stage 0.0 (TID 1). 2254 bytes result sent to driver
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(0,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=2254 cap=2254]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(0,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=2254 cap=2254]),false)
2015-09-25 18:49:31 DEBUG TaskSchedulerImpl:63 - parentName: , name: TaskSet_0, runningTasks: 1
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.322635 ms) AkkaMessage(StatusUpdate(0,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=2254 cap=2254]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(1,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=2254 cap=2254]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(1,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=2254 cap=2254]),false)
2015-09-25 18:49:31 DEBUG TaskSchedulerImpl:63 - parentName: , name: TaskSet_0, runningTasks: 0
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (5.475868 ms) AkkaMessage(StatusUpdate(1,FINISHED,java.nio.HeapByteBuffer[pos=690 lim=2254 cap=2254]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 INFO  TaskSetManager:59 - Finished task 0.0 in stage 0.0 (TID 0) in 1897 ms on localhost (1/2)
2015-09-25 18:49:31 INFO  TaskSetManager:59 - Finished task 1.0 in stage 0.0 (TID 1) in 1882 ms on localhost (2/2)
2015-09-25 18:49:31 INFO  TaskSchedulerImpl:59 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2015-09-25 18:49:31 DEBUG DAGScheduler:63 - ShuffleMapTask finished on driver
2015-09-25 18:49:31 DEBUG DAGScheduler:63 - submitStage(ResultStage 1)
2015-09-25 18:49:31 DEBUG DAGScheduler:63 - missing: List(ShuffleMapStage 0)
2015-09-25 18:49:31 DEBUG DAGScheduler:63 - submitStage(ShuffleMapStage 0)
2015-09-25 18:49:31 DEBUG DAGScheduler:63 - ShuffleMapTask finished on driver
2015-09-25 18:49:31 INFO  DAGScheduler:59 - ShuffleMapStage 0 (map at <console>:23) finished in 1.918 s
2015-09-25 18:49:31 INFO  DAGScheduler:59 - looking for newly runnable stages
2015-09-25 18:49:31 INFO  DAGScheduler:59 - running: Set()
2015-09-25 18:49:31 INFO  DAGScheduler:59 - waiting: Set(ResultStage 1)
2015-09-25 18:49:31 INFO  DAGScheduler:59 - failed: Set()
2015-09-25 18:49:31 DEBUG MapOutputTrackerMaster:63 - Increasing epoch to 1
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@732713b3),true) from Actor[akka://sparkDriver/temp/$P]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@732713b3),true)
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.29637 ms) AkkaMessage(GetLocationsMultipleBlockIds([Lorg.apache.spark.storage.BlockId;@732713b3),true) from Actor[akka://sparkDriver/temp/$P]
2015-09-25 18:49:31 INFO  DAGScheduler:59 - Missing parents for ResultStage 1: List()
2015-09-25 18:49:31 INFO  DAGScheduler:59 - Submitting ResultStage 1 (MapPartitionsRDD[5] at saveAsTextFile at <console>:26), which is now runnable
2015-09-25 18:49:31 DEBUG DAGScheduler:63 - submitMissingTasks(ResultStage 1)
2015-09-25 18:49:31 INFO  MemoryStore:59 - ensureFreeSpace(95376) called with curMem=126793, maxMem=555755765
2015-09-25 18:49:31 INFO  MemoryStore:59 - Block broadcast_2 stored as values in memory (estimated size 93.1 KB, free 529.8 MB)
2015-09-25 18:49:31 DEBUG BlockManager:63 - Put block broadcast_2 locally took  0 ms
2015-09-25 18:49:31 DEBUG BlockManager:63 - Putting block broadcast_2 without replication took  0 ms
2015-09-25 18:49:31 INFO  MemoryStore:59 - ensureFreeSpace(31306) called with curMem=222169, maxMem=555755765
2015-09-25 18:49:31 INFO  MemoryStore:59 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 30.6 KB, free 529.8 MB)
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),31306,0,0),true) from Actor[akka://sparkDriver/temp/$Q]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),31306,0,0),true)
2015-09-25 18:49:31 INFO  BlockManagerInfo:59 - Added broadcast_2_piece0 in memory on localhost:53087 (size: 30.6 KB, free: 530.0 MB)
2015-09-25 18:49:31 DEBUG BlockManagerMaster:63 - Updated info of block broadcast_2_piece0
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.586418 ms) AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_2_piece0,StorageLevel(false, true, false, false, 1),31306,0,0),true) from Actor[akka://sparkDriver/temp/$Q]
2015-09-25 18:49:31 DEBUG BlockManager:63 - Told master about block broadcast_2_piece0
2015-09-25 18:49:31 DEBUG BlockManager:63 - Put block broadcast_2_piece0 locally took  2 ms
2015-09-25 18:49:31 DEBUG BlockManager:63 - Putting block broadcast_2_piece0 without replication took  2 ms
2015-09-25 18:49:31 INFO  SparkContext:59 - Created broadcast 2 from broadcast at DAGScheduler.scala:861
2015-09-25 18:49:31 INFO  DAGScheduler:59 - Submitting 2 missing tasks from ResultStage 1 (MapPartitionsRDD[5] at saveAsTextFile at <console>:26)
2015-09-25 18:49:31 DEBUG DAGScheduler:63 - New pending tasks: Set(ResultTask(1, 0), ResultTask(1, 1))
2015-09-25 18:49:31 INFO  TaskSchedulerImpl:59 - Adding task set 1.0 with 2 tasks
2015-09-25 18:49:31 DEBUG TaskSetManager:63 - Epoch for TaskSet 1.0: 1
2015-09-25 18:49:31 DEBUG TaskSetManager:63 - Valid locality levels for TaskSet 1.0: NO_PREF, ANY
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ReviveOffers,false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ReviveOffers,false)
2015-09-25 18:49:31 DEBUG TaskSchedulerImpl:63 - parentName: , name: TaskSet_1, runningTasks: 0
2015-09-25 18:49:31 INFO  TaskSetManager:59 - Starting task 0.0 in stage 1.0 (TID 2, localhost, PROCESS_LOCAL, 1901 bytes)
2015-09-25 18:49:31 INFO  TaskSetManager:59 - Starting task 1.0 in stage 1.0 (TID 3, localhost, PROCESS_LOCAL, 1901 bytes)
2015-09-25 18:49:31 DEBUG TaskSetManager:63 - No tasks for locality level NO_PREF, so moving to locality level ANY
2015-09-25 18:49:31 INFO  Executor:59 - Running task 0.0 in stage 1.0 (TID 2)
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (4.508873 ms) AkkaMessage(ReviveOffers,false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(2,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 INFO  Executor:59 - Running task 1.0 in stage 1.0 (TID 3)
2015-09-25 18:49:31 DEBUG Executor:63 - Task 2's epoch is 1
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(2,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false)
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting local block broadcast_2
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.477013 ms) AkkaMessage(StatusUpdate(2,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(3,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG Executor:63 - Task 3's epoch is 1
2015-09-25 18:49:31 DEBUG BlockManager:63 - Level for block broadcast_2 is StorageLevel(true, true, false, true, 1)
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting block broadcast_2 from memory
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(3,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false)
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.88398 ms) AkkaMessage(StatusUpdate(3,RUNNING,java.nio.HeapByteBuffer[pos=0 lim=0 cap=0]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting local block broadcast_2
2015-09-25 18:49:31 DEBUG BlockManager:63 - Level for block broadcast_2 is StorageLevel(true, true, false, true, 1)
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting block broadcast_2 from memory
2015-09-25 18:49:31 INFO  deprecation:840 - mapred.output.dir is deprecated. Instead, use mapreduce.output.fileoutputformat.outputdir
2015-09-25 18:49:31 INFO  deprecation:840 - mapred.output.key.class is deprecated. Instead, use mapreduce.job.output.key.class
2015-09-25 18:49:31 INFO  deprecation:840 - mapred.output.value.class is deprecated. Instead, use mapreduce.job.output.value.class
2015-09-25 18:49:31 INFO  deprecation:840 - mapred.working.dir is deprecated. Instead, use mapreduce.job.working.dir
2015-09-25 18:49:31 DEBUG CacheManager:63 - Looking for partition rdd_4_0
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting local block rdd_4_0
2015-09-25 18:49:31 DEBUG BlockManager:63 - Block rdd_4_0 not registered locally
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting remote block rdd_4_0
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(GetLocations(rdd_4_0),true) from Actor[akka://sparkDriver/temp/$R]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(GetLocations(rdd_4_0),true)
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.422882 ms) AkkaMessage(GetLocations(rdd_4_0),true) from Actor[akka://sparkDriver/temp/$R]
2015-09-25 18:49:31 DEBUG BlockManager:63 - Block rdd_4_0 not found
2015-09-25 18:49:31 INFO  CacheManager:59 - Partition rdd_4_0 not found, computing it
2015-09-25 18:49:31 DEBUG CacheManager:63 - Looking for partition rdd_4_1
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting local block rdd_4_1
2015-09-25 18:49:31 DEBUG BlockManager:63 - Block rdd_4_1 not registered locally
2015-09-25 18:49:31 DEBUG BlockManager:63 - Getting remote block rdd_4_1
2015-09-25 18:49:31 DEBUG MapOutputTrackerMaster:63 - Fetching outputs for shuffle 0, reduce 0
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(GetLocations(rdd_4_1),true) from Actor[akka://sparkDriver/temp/$S]
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(GetLocations(rdd_4_1),true)
2015-09-25 18:49:31 DEBUG BlockManager:63 - Block rdd_4_1 not found
2015-09-25 18:49:31 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.430808 ms) AkkaMessage(GetLocations(rdd_4_1),true) from Actor[akka://sparkDriver/temp/$S]
2015-09-25 18:49:31 INFO  CacheManager:59 - Partition rdd_4_1 not found, computing it
2015-09-25 18:49:31 DEBUG MapOutputTrackerMaster:63 - Fetching outputs for shuffle 0, reduce 1
2015-09-25 18:49:31 DEBUG ShuffleBlockFetcherIterator:63 - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2015-09-25 18:49:31 DEBUG ShuffleBlockFetcherIterator:63 - maxBytesInFlight: 50331648, targetRequestSize: 10066329
2015-09-25 18:49:31 INFO  ShuffleBlockFetcherIterator:59 - Getting 2 non-empty blocks out of 2 blocks
2015-09-25 18:49:31 INFO  ShuffleBlockFetcherIterator:59 - Getting 2 non-empty blocks out of 2 blocks
2015-09-25 18:49:31 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-09-25 18:49:31 INFO  ShuffleBlockFetcherIterator:59 - Started 0 remote fetches in 5 ms
2015-09-25 18:49:31 DEBUG ShuffleBlockFetcherIterator:63 - Got local blocks in  11 ms
2015-09-25 18:49:31 DEBUG ShuffleBlockFetcherIterator:63 - Got local blocks in  11 ms
2015-09-25 18:49:32 DEBUG ContextCleaner:63 - Got cleaning task CleanBroadcast(1)
2015-09-25 18:49:32 DEBUG ContextCleaner:63 - Cleaning broadcast 1
2015-09-25 18:49:32 DEBUG TorrentBroadcast:63 - Unpersisting TorrentBroadcast 1
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(RemoveBroadcast(1,true),true) from Actor[akka://sparkDriver/temp/$T]
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(RemoveBroadcast(1,true),true)
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(RemoveBroadcast(1,true),true) from Actor[akka://sparkDriver/temp/$U]
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(RemoveBroadcast(1,true),true)
2015-09-25 18:49:32 DEBUG BlockManagerSlaveEndpoint:63 - removing broadcast 1
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (13.971706 ms) AkkaMessage(RemoveBroadcast(1,true),true) from Actor[akka://sparkDriver/temp/$U]
2015-09-25 18:49:32 DEBUG BlockManager:63 - Removing broadcast 1
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (16.471605 ms) AkkaMessage(RemoveBroadcast(1,true),true) from Actor[akka://sparkDriver/temp/$T]
2015-09-25 18:49:32 DEBUG BlockManager:63 - Removing block broadcast_1
2015-09-25 18:49:32 DEBUG MemoryStore:63 - Block broadcast_1 of size 4168 dropped from memory (free 555506458)
2015-09-25 18:49:32 DEBUG BlockManager:63 - Removing block broadcast_1_piece0
2015-09-25 18:49:32 DEBUG MemoryStore:63 - Block broadcast_1_piece0 of size 2312 dropped from memory (free 555508770)
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_1_piece0,StorageLevel(false, false, false, false, 1),0,0,0),true) from Actor[akka://sparkDriver/temp/$V]
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_1_piece0,StorageLevel(false, false, false, false, 1),0,0,0),true)
2015-09-25 18:49:32 INFO  BlockManagerInfo:59 - Removed broadcast_1_piece0 on localhost:53087 in memory (size: 2.3 KB, free: 530.0 MB)
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.54266 ms) AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),broadcast_1_piece0,StorageLevel(false, false, false, false, 1),0,0,0),true) from Actor[akka://sparkDriver/temp/$V]
2015-09-25 18:49:32 DEBUG BlockManagerMaster:63 - Updated info of block broadcast_1_piece0
2015-09-25 18:49:32 DEBUG BlockManager:63 - Told master about block broadcast_1_piece0
2015-09-25 18:49:32 DEBUG BlockManagerSlaveEndpoint:63 - Done removing broadcast 1, response is 2
2015-09-25 18:49:32 DEBUG ContextCleaner:63 - Cleaned broadcast 1
2015-09-25 18:49:32 DEBUG BlockManagerSlaveEndpoint:63 - Sent response: 2 to AkkaRpcEndpointRef(Actor[akka://sparkDriver/temp/$U])
2015-09-25 18:49:32 INFO  MemoryStore:59 - ensureFreeSpace(6869952) called with curMem=246995, maxMem=555755765
2015-09-25 18:49:32 INFO  MemoryStore:59 - Block rdd_4_1 stored as values in memory (estimated size 6.6 MB, free 523.2 MB)
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),rdd_4_1,StorageLevel(false, true, false, true, 1),6869952,0,0),true) from Actor[akka://sparkDriver/temp/$W]
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),rdd_4_1,StorageLevel(false, true, false, true, 1),6869952,0,0),true)
2015-09-25 18:49:32 INFO  BlockManagerInfo:59 - Added rdd_4_1 in memory on localhost:53087 (size: 6.6 MB, free: 523.4 MB)
2015-09-25 18:49:32 DEBUG BlockManagerMaster:63 - Updated info of block rdd_4_1
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.053622 ms) AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),rdd_4_1,StorageLevel(false, true, false, true, 1),6869952,0,0),true) from Actor[akka://sparkDriver/temp/$W]
2015-09-25 18:49:32 DEBUG BlockManager:63 - Told master about block rdd_4_1
2015-09-25 18:49:32 DEBUG BlockManager:63 - Put block rdd_4_1 locally took  3 ms
2015-09-25 18:49:32 DEBUG BlockManager:63 - Putting block rdd_4_1 without replication took  3 ms
2015-09-25 18:49:32 DEBUG SparkHadoopUtil:84 - Couldn't find method for retrieving thread-level FileSystem output data
java.lang.NoSuchMethodException: org.apache.hadoop.fs.FileSystem$Statistics.getThreadStatistics()
	at java.lang.Class.getDeclaredMethod(Class.java:2130)
	at org.apache.spark.util.Utils$.invoke(Utils.scala:1991)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.deploy.SparkHadoopUtil.getFileSystemThreadStatistics(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil.getFSBytesWrittenOnThreadCallback(SparkHadoopUtil.scala:164)
	at org.apache.spark.rdd.PairRDDFunctions.org$apache$spark$rdd$PairRDDFunctions$$initHadoopOutputMetrics(PairRDDFunctions.scala:1129)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1101)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-09-25 18:49:32 INFO  MemoryStore:59 - ensureFreeSpace(6758904) called with curMem=7116947, maxMem=555755765
2015-09-25 18:49:32 INFO  MemoryStore:59 - Block rdd_4_0 stored as values in memory (estimated size 6.4 MB, free 516.8 MB)
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),rdd_4_0,StorageLevel(false, true, false, true, 1),6758904,0,0),true) from Actor[akka://sparkDriver/temp/$X]
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),rdd_4_0,StorageLevel(false, true, false, true, 1),6758904,0,0),true)
2015-09-25 18:49:32 INFO  BlockManagerInfo:59 - Added rdd_4_0 in memory on localhost:53087 (size: 6.4 MB, free: 517.0 MB)
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.785434 ms) AkkaMessage(UpdateBlockInfo(BlockManagerId(driver, localhost, 53087),rdd_4_0,StorageLevel(false, true, false, true, 1),6758904,0,0),true) from Actor[akka://sparkDriver/temp/$X]
2015-09-25 18:49:32 DEBUG BlockManagerMaster:63 - Updated info of block rdd_4_0
2015-09-25 18:49:32 DEBUG BlockManager:63 - Told master about block rdd_4_0
2015-09-25 18:49:32 DEBUG BlockManager:63 - Put block rdd_4_0 locally took  2 ms
2015-09-25 18:49:32 DEBUG BlockManager:63 - Putting block rdd_4_0 without replication took  3 ms
2015-09-25 18:49:32 DEBUG SparkHadoopUtil:84 - Couldn't find method for retrieving thread-level FileSystem output data
java.lang.NoSuchMethodException: org.apache.hadoop.fs.FileSystem$Statistics.getThreadStatistics()
	at java.lang.Class.getDeclaredMethod(Class.java:2130)
	at org.apache.spark.util.Utils$.invoke(Utils.scala:1991)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil$$anonfun$getFileSystemThreadStatistics$1.apply(SparkHadoopUtil.scala:179)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.TraversableLike$$anonfun$map$1.apply(TraversableLike.scala:244)
	at scala.collection.Iterator$class.foreach(Iterator.scala:727)
	at scala.collection.AbstractIterator.foreach(Iterator.scala:1157)
	at scala.collection.IterableLike$class.foreach(IterableLike.scala:72)
	at scala.collection.AbstractIterable.foreach(Iterable.scala:54)
	at scala.collection.TraversableLike$class.map(TraversableLike.scala:244)
	at scala.collection.AbstractTraversable.map(Traversable.scala:105)
	at org.apache.spark.deploy.SparkHadoopUtil.getFileSystemThreadStatistics(SparkHadoopUtil.scala:179)
	at org.apache.spark.deploy.SparkHadoopUtil.getFSBytesWrittenOnThreadCallback(SparkHadoopUtil.scala:164)
	at org.apache.spark.rdd.PairRDDFunctions.org$apache$spark$rdd$PairRDDFunctions$$initHadoopOutputMetrics(PairRDDFunctions.scala:1129)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1101)
	at org.apache.spark.rdd.PairRDDFunctions$$anonfun$saveAsHadoopDataset$1$$anonfun$13.apply(PairRDDFunctions.scala:1095)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:66)
	at org.apache.spark.scheduler.Task.run(Task.scala:88)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:214)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)
2015-09-25 18:49:32 INFO  FileOutputCommitter:439 - Saved output of task 'attempt_201509251849_0001_m_000001_3' to file:/home/aparna/Downloads/projects/wordcounttxt/_temporary/0/task_201509251849_0001_m_000001
2015-09-25 18:49:32 INFO  SparkHadoopMapRedUtil:59 - attempt_201509251849_0001_m_000001_3: Committed
2015-09-25 18:49:32 INFO  Executor:59 - Finished task 1.0 in stage 1.0 (TID 3). 1745 bytes result sent to driver
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(3,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=1745 cap=1745]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(3,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=1745 cap=1745]),false)
2015-09-25 18:49:32 DEBUG TaskSchedulerImpl:63 - parentName: , name: TaskSet_1, runningTasks: 1
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.725974 ms) AkkaMessage(StatusUpdate(3,FINISHED,java.nio.HeapByteBuffer[pos=656 lim=1745 cap=1745]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:32 INFO  FileOutputCommitter:439 - Saved output of task 'attempt_201509251849_0001_m_000000_2' to file:/home/aparna/Downloads/projects/wordcounttxt/_temporary/0/task_201509251849_0001_m_000000
2015-09-25 18:49:32 INFO  TaskSetManager:59 - Finished task 1.0 in stage 1.0 (TID 3) in 776 ms on localhost (1/2)
2015-09-25 18:49:32 INFO  SparkHadoopMapRedUtil:59 - attempt_201509251849_0001_m_000000_2: Committed
2015-09-25 18:49:32 INFO  Executor:59 - Finished task 0.0 in stage 1.0 (TID 2). 1745 bytes result sent to driver
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(StatusUpdate(2,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=1745 cap=1745]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(StatusUpdate(2,FINISHED,java.nio.HeapByteBuffer[pos=0 lim=1745 cap=1745]),false)
2015-09-25 18:49:32 DEBUG TaskSchedulerImpl:63 - parentName: , name: TaskSet_1, runningTasks: 0
2015-09-25 18:49:32 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.773713 ms) AkkaMessage(StatusUpdate(2,FINISHED,java.nio.HeapByteBuffer[pos=1313 lim=1745 cap=1745]),false) from Actor[akka://sparkDriver/deadLetters]
2015-09-25 18:49:32 INFO  TaskSetManager:59 - Finished task 0.0 in stage 1.0 (TID 2) in 789 ms on localhost (2/2)
2015-09-25 18:49:32 INFO  TaskSchedulerImpl:59 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2015-09-25 18:49:32 INFO  DAGScheduler:59 - ResultStage 1 (saveAsTextFile at <console>:26) finished in 0.790 s
2015-09-25 18:49:32 DEBUG DAGScheduler:63 - After removal of stage 1, remaining stages = 1
2015-09-25 18:49:32 DEBUG DAGScheduler:63 - After removal of stage 0, remaining stages = 0
2015-09-25 18:49:32 INFO  DAGScheduler:59 - Job 0 finished: saveAsTextFile at <console>:26, took 2.836548 s
2015-09-25 18:49:32 DEBUG FileOutputCommitter:337 - Merging data from RawLocalFileStatus{path=file:/home/aparna/Downloads/projects/wordcounttxt/_temporary/0/task_201509251849_0001_m_000000; isDirectory=true; modification_time=1443221372000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/aparna/Downloads/projects/wordcounttxt
2015-09-25 18:49:32 DEBUG FileOutputCommitter:337 - Merging data from RawLocalFileStatus{path=file:/home/aparna/Downloads/projects/wordcounttxt/_temporary/0/task_201509251849_0001_m_000000/part-00000; isDirectory=false; length=1068457; replication=1; blocksize=33554432; modification_time=1443221372000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/aparna/Downloads/projects/wordcounttxt/part-00000
2015-09-25 18:49:32 DEBUG FileOutputCommitter:337 - Merging data from RawLocalFileStatus{path=file:/home/aparna/Downloads/projects/wordcounttxt/_temporary/0/task_201509251849_0001_m_000001; isDirectory=true; modification_time=1443221372000; access_time=0; owner=; group=; permission=rwxrwxrwx; isSymlink=false} to file:/home/aparna/Downloads/projects/wordcounttxt
2015-09-25 18:49:32 DEBUG FileOutputCommitter:337 - Merging data from RawLocalFileStatus{path=file:/home/aparna/Downloads/projects/wordcounttxt/_temporary/0/task_201509251849_0001_m_000001/part-00001; isDirectory=false; length=1068607; replication=1; blocksize=33554432; modification_time=1443221372000; access_time=0; owner=; group=; permission=rw-rw-rw-; isSymlink=false} to file:/home/aparna/Downloads/projects/wordcounttxt/part-00001
2015-09-25 18:49:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@673fa0b7,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Y]
2015-09-25 18:49:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@673fa0b7,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.659328 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@673fa0b7,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Y]
2015-09-25 18:49:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Z]
2015-09-25 18:49:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.722995 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Z]
2015-09-25 18:49:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$0]
2015-09-25 18:49:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:49:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.78961 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$0]
2015-09-25 18:49:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5c73a03d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$1]
2015-09-25 18:49:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5c73a03d,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.256261 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5c73a03d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$1]
2015-09-25 18:49:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$2]
2015-09-25 18:49:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.2677 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$2]
2015-09-25 18:49:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@569d91bc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$3]
2015-09-25 18:49:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@569d91bc,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.574878 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@569d91bc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$3]
2015-09-25 18:49:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$4]
2015-09-25 18:49:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:49:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.69259 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$4]
2015-09-25 18:50:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7c073831,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$5]
2015-09-25 18:50:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7c073831,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.31811 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7c073831,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$5]
2015-09-25 18:50:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$6]
2015-09-25 18:50:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.432862 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$6]
2015-09-25 18:50:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@32333a1f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$7]
2015-09-25 18:50:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@32333a1f,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.57355 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@32333a1f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$7]
2015-09-25 18:50:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$8]
2015-09-25 18:50:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.731049 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$8]
2015-09-25 18:50:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@420d57a6,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$9]
2015-09-25 18:50:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@420d57a6,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.594147 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@420d57a6,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$9]
2015-09-25 18:50:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$+]
2015-09-25 18:50:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.733439 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$+]
2015-09-25 18:50:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7300162c,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$~]
2015-09-25 18:50:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7300162c,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.570899 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7300162c,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$~]
2015-09-25 18:50:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$ab]
2015-09-25 18:50:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.653559 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$ab]
2015-09-25 18:50:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$bb]
2015-09-25 18:50:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:50:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.843228 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$bb]
2015-09-25 18:50:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@492a6981,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$cb]
2015-09-25 18:50:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@492a6981,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.761795 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@492a6981,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$cb]
2015-09-25 18:50:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$db]
2015-09-25 18:50:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.744935 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$db]
2015-09-25 18:50:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@439d92d1,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$eb]
2015-09-25 18:50:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@439d92d1,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.693186 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@439d92d1,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$eb]
2015-09-25 18:50:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$fb]
2015-09-25 18:50:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:50:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.978706 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$fb]
2015-09-25 18:51:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@ca90625,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$gb]
2015-09-25 18:51:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@ca90625,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.404706 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@ca90625,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$gb]
2015-09-25 18:51:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$hb]
2015-09-25 18:51:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.464411 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$hb]
2015-09-25 18:51:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2761366d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$ib]
2015-09-25 18:51:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2761366d,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.68842 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@2761366d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$ib]
2015-09-25 18:51:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$jb]
2015-09-25 18:51:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.644704 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$jb]
2015-09-25 18:51:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5423e5db,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$kb]
2015-09-25 18:51:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5423e5db,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.226385 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5423e5db,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$kb]
2015-09-25 18:51:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$lb]
2015-09-25 18:51:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.27035 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$lb]
2015-09-25 18:51:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4edfe8bf,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$mb]
2015-09-25 18:51:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4edfe8bf,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.640675 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4edfe8bf,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$mb]
2015-09-25 18:51:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$nb]
2015-09-25 18:51:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.011181 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$nb]
2015-09-25 18:51:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$ob]
2015-09-25 18:51:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:51:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.339933 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$ob]
2015-09-25 18:51:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@51fa345d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$pb]
2015-09-25 18:51:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@51fa345d,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.273756 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@51fa345d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$pb]
2015-09-25 18:51:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$qb]
2015-09-25 18:51:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.383241 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$qb]
2015-09-25 18:51:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@a83476f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$rb]
2015-09-25 18:51:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@a83476f,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.243664 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@a83476f,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$rb]
2015-09-25 18:51:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$sb]
2015-09-25 18:51:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:51:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.266264 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$sb]
2015-09-25 18:52:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@24ffca0c,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$tb]
2015-09-25 18:52:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@24ffca0c,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.328429 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@24ffca0c,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$tb]
2015-09-25 18:52:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$ub]
2015-09-25 18:52:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.346514 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$ub]
2015-09-25 18:52:13 DEBUG nio:842 - created SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=0,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=0}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-14,l=0,c=0},r=0}
2015-09-25 18:52:13 DEBUG HttpParser:281 - filled 296/296
2015-09-25 18:52:13 DEBUG Server:365 - REQUEST /jobs on AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=1
2015-09-25 18:52:13 DEBUG ContextHandler:942 - scope null||/jobs @ o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:52:13 DEBUG Server:367 - RESPONSE /jobs  302 handled=true
2015-09-25 18:52:13 DEBUG AsyncHttpConnection:211 - Enabled read interest SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=0r}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=4,h=0,b=-1,c=-1},p=HttpParser{s=0,l=10,c=0},r=1}
2015-09-25 18:52:13 DEBUG HttpParser:281 - filled 297/297
2015-09-25 18:52:13 DEBUG Server:365 - REQUEST /jobs/ on AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=2
2015-09-25 18:52:13 DEBUG ContextHandler:942 - scope null||/jobs/ @ o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:52:13 DEBUG ContextHandler:1014 - context=/jobs||/ @ o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:52:13 DEBUG ServletHandler:414 - servlet /jobs|/|null -> org.apache.spark.ui.JettyUtils$$anon$1-15e08615
2015-09-25 18:52:13 DEBUG ServletHandler:476 - chain=null
2015-09-25 18:52:13 DEBUG SecurityManager:63 - user=null aclsEnabled=false viewAcls=aparna
2015-09-25 18:52:13 DEBUG Server:367 - RESPONSE /jobs/  200 handled=true
2015-09-25 18:52:13 DEBUG AsyncHttpConnection:211 - Enabled read interest SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=4w}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=4,h=0,b=0,c=-1},p=HttpParser{s=0,l=10,c=0},r=2}
2015-09-25 18:52:13 DEBUG HttpParser:281 - filled 0/0
2015-09-25 18:52:14 DEBUG HttpParser:281 - filled 303/303
2015-09-25 18:52:14 DEBUG Server:365 - REQUEST /favicon.ico on AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=3
2015-09-25 18:52:14 DEBUG ContextHandler:942 - scope null||/favicon.ico @ o.e.j.s.ServletContextHandler{/,null}
2015-09-25 18:52:14 DEBUG ContextHandler:1014 - context=||/favicon.ico @ o.e.j.s.ServletContextHandler{/,null}
2015-09-25 18:52:14 DEBUG ServletHandler:414 - servlet |/favicon.ico|null -> org.apache.spark.ui.JettyUtils$$anon$2-4243341e
2015-09-25 18:52:14 DEBUG ServletHandler:476 - chain=null
2015-09-25 18:52:14 DEBUG Server:367 - RESPONSE /favicon.ico  302 handled=true
2015-09-25 18:52:14 DEBUG AsyncHttpConnection:211 - Enabled read interest SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=1r}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=4,h=0,b=-1,c=-1},p=HttpParser{s=0,l=10,c=0},r=3}
2015-09-25 18:52:14 DEBUG HttpParser:281 - filled 296/296
2015-09-25 18:52:14 DEBUG Server:365 - REQUEST /jobs on AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=4
2015-09-25 18:52:14 DEBUG ContextHandler:942 - scope null||/jobs @ o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:52:14 DEBUG Server:367 - RESPONSE /jobs  302 handled=true
2015-09-25 18:52:14 DEBUG AsyncHttpConnection:211 - Enabled read interest SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=1r}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=4,h=0,b=-1,c=-1},p=HttpParser{s=0,l=10,c=0},r=4}
2015-09-25 18:52:14 DEBUG HttpParser:281 - filled 0/0
2015-09-25 18:52:14 DEBUG HttpParser:281 - filled 297/297
2015-09-25 18:52:14 DEBUG Server:365 - REQUEST /jobs/ on AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=5
2015-09-25 18:52:14 DEBUG ContextHandler:942 - scope null||/jobs/ @ o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:52:14 DEBUG ContextHandler:1014 - context=/jobs||/ @ o.e.j.s.ServletContextHandler{/jobs,null}
2015-09-25 18:52:14 DEBUG ServletHandler:414 - servlet /jobs|/|null -> org.apache.spark.ui.JettyUtils$$anon$1-15e08615
2015-09-25 18:52:14 DEBUG ServletHandler:476 - chain=null
2015-09-25 18:52:14 DEBUG SecurityManager:63 - user=null aclsEnabled=false viewAcls=aparna
2015-09-25 18:52:14 DEBUG Server:367 - RESPONSE /jobs/  200 handled=true
2015-09-25 18:52:14 DEBUG AsyncHttpConnection:211 - Enabled read interest SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=4w}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=4,h=0,b=0,c=-1},p=HttpParser{s=0,l=10,c=0},r=5}
2015-09-25 18:52:14 DEBUG HttpParser:281 - filled 0/0
2015-09-25 18:52:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@6fb9ee75,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$vb]
2015-09-25 18:52:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@6fb9ee75,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.251366 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@6fb9ee75,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$vb]
2015-09-25 18:52:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$wb]
2015-09-25 18:52:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.264072 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$wb]
2015-09-25 18:52:16 DEBUG HttpParser:281 - filled 343/343
2015-09-25 18:52:16 DEBUG Server:365 - REQUEST /jobs/job on AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=6
2015-09-25 18:52:16 DEBUG ContextHandler:942 - scope null||/jobs/job @ o.e.j.s.ServletContextHandler{/jobs/job,null}
2015-09-25 18:52:16 DEBUG Server:367 - RESPONSE /jobs/job  302 handled=true
2015-09-25 18:52:16 DEBUG AsyncHttpConnection:211 - Enabled read interest SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=1r}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=4,h=0,b=-1,c=-1},p=HttpParser{s=0,l=10,c=0},r=6}
2015-09-25 18:52:16 DEBUG HttpParser:281 - filled 0/0
2015-09-25 18:52:16 DEBUG HttpParser:281 - filled 344/344
2015-09-25 18:52:16 DEBUG Server:365 - REQUEST /jobs/job/ on AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-5,l=10,c=0},r=7
2015-09-25 18:52:16 DEBUG ContextHandler:942 - scope null||/jobs/job/ @ o.e.j.s.ServletContextHandler{/jobs/job,null}
2015-09-25 18:52:16 DEBUG ContextHandler:1014 - context=/jobs/job||/ @ o.e.j.s.ServletContextHandler{/jobs/job,null}
2015-09-25 18:52:16 DEBUG ServletHandler:414 - servlet /jobs/job|/|null -> org.apache.spark.ui.JettyUtils$$anon$1-18715bb
2015-09-25 18:52:16 DEBUG ServletHandler:476 - chain=null
2015-09-25 18:52:16 DEBUG SecurityManager:63 - user=null aclsEnabled=false viewAcls=aparna
2015-09-25 18:52:16 DEBUG RDDOperationGraph:63 - digraph G {
  subgraph clusterstage_0 {
    label="Stage 0";
    subgraph cluster2 {
      label="map";
      3 [label="MapPartitionsRDD [3]"];
    }
    subgraph cluster0 {
      label="textFile";
      1 [label="MapPartitionsRDD [1]"];
      0 [label="/home/aparna/Downloads/RonaldoTweets.txt [0]"];
    }
    subgraph cluster1 {
      label="flatMap";
      2 [label="MapPartitionsRDD [2]"];
    }
    subgraph cluster0 {
      label="textFile";
      1 [label="MapPartitionsRDD [1]"];
      0 [label="/home/aparna/Downloads/RonaldoTweets.txt [0]"];
    }
  }
  2->3;
  0->1;
  1->2;
}
2015-09-25 18:52:16 DEBUG RDDOperationGraph:63 - digraph G {
  subgraph clusterstage_1 {
    label="Stage 1";
    subgraph cluster4 {
      label="saveAsTextFile";
      5 [label="MapPartitionsRDD [5]"];
    }
    subgraph cluster3 {
      label="reduceByKey";
      4 [label="ShuffledRDD [4]"];
    }
  }
  4->5;
}
2015-09-25 18:52:16 DEBUG Server:367 - RESPONSE /jobs/job/  200 handled=true
2015-09-25 18:52:16 DEBUG AsyncHttpConnection:211 - Enabled read interest SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=4w}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=4,h=0,b=0,c=-1},p=HttpParser{s=0,l=10,c=0},r=7}
2015-09-25 18:52:16 DEBUG HttpParser:281 - filled 0/0
2015-09-25 18:52:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5e12792d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$xb]
2015-09-25 18:52:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5e12792d,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.264108 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@5e12792d,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$xb]
2015-09-25 18:52:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$yb]
2015-09-25 18:52:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.332406 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$yb]
2015-09-25 18:52:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4ebae5bf,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$zb]
2015-09-25 18:52:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4ebae5bf,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.206669 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4ebae5bf,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$zb]
2015-09-25 18:52:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Ab]
2015-09-25 18:52:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.25897 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Ab]
2015-09-25 18:52:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$Bb]
2015-09-25 18:52:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:52:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.404843 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$Bb]
2015-09-25 18:52:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@144ff9ce,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Cb]
2015-09-25 18:52:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@144ff9ce,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.536344 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@144ff9ce,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Cb]
2015-09-25 18:52:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Db]
2015-09-25 18:52:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (1.000025 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Db]
2015-09-25 18:52:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4b5a0ccd,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Eb]
2015-09-25 18:52:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4b5a0ccd,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.212641 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4b5a0ccd,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Eb]
2015-09-25 18:52:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Fb]
2015-09-25 18:52:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:52:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.261083 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Fb]
2015-09-25 18:53:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@6342d267,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Gb]
2015-09-25 18:53:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@6342d267,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.227703 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@6342d267,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Gb]
2015-09-25 18:53:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Hb]
2015-09-25 18:53:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.272023 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Hb]
2015-09-25 18:53:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4ce6dfc4,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Ib]
2015-09-25 18:53:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4ce6dfc4,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.233355 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4ce6dfc4,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Ib]
2015-09-25 18:53:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Jb]
2015-09-25 18:53:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.50739 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Jb]
2015-09-25 18:53:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@34a56774,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Kb]
2015-09-25 18:53:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@34a56774,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.637913 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@34a56774,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Kb]
2015-09-25 18:53:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Lb]
2015-09-25 18:53:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.619125 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Lb]
2015-09-25 18:53:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7933bbdc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Mb]
2015-09-25 18:53:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7933bbdc,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.279954 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7933bbdc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Mb]
2015-09-25 18:53:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Nb]
2015-09-25 18:53:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.644987 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Nb]
2015-09-25 18:53:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$Ob]
2015-09-25 18:53:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:53:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.797903 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$Ob]
2015-09-25 18:53:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@60bd2e58,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Pb]
2015-09-25 18:53:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@60bd2e58,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.238318 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@60bd2e58,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Pb]
2015-09-25 18:53:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Qb]
2015-09-25 18:53:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.316409 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Qb]
2015-09-25 18:53:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@bd73a08,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Rb]
2015-09-25 18:53:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@bd73a08,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.756763 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@bd73a08,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Rb]
2015-09-25 18:53:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Sb]
2015-09-25 18:53:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:53:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.765563 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Sb]
2015-09-25 18:54:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4cbe52d9,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Tb]
2015-09-25 18:54:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4cbe52d9,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.532631 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@4cbe52d9,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Tb]
2015-09-25 18:54:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Ub]
2015-09-25 18:54:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.790025 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Ub]
2015-09-25 18:54:11 DEBUG ChannelEndPoint:118 - ishut SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=false,oshut=false,rb=false,wb=false,w=true,i=1r}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=-14,l=0,c=-3},r=7}
2015-09-25 18:54:11 DEBUG HttpParser:281 - filled -1/0
2015-09-25 18:54:11 DEBUG AsyncHttpConnection:145 - Disabled read interest while writing response SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=true,oshut=false,rb=false,wb=false,w=true,i=1r}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=0,l=0,c=-3},r=7}
2015-09-25 18:54:11 DEBUG ChannelEndPoint:209 - close SCEP@28c14a21{l(/127.0.0.1:50907)<->r(/127.0.0.1:4040),s=1,open=true,ishut=true,oshut=false,rb=false,wb=false,w=true,i=1r}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=0,l=0,c=-3},r=7}
2015-09-25 18:54:11 DEBUG nio:851 - destroyEndPoint SCEP@28c14a21{l(null)<->r(0.0.0.0/0.0.0.0:4040),s=0,open=false,ishut=true,oshut=true,rb=false,wb=false,w=true,i=1!}-{AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=0,l=0,c=-3},r=7}
2015-09-25 18:54:11 DEBUG AbstractHttpConnection:738 - closed AsyncHttpConnection@1b28274a,g=HttpGenerator{s=0,h=-1,b=-1,c=-1},p=HttpParser{s=0,l=0,c=-3},r=7
2015-09-25 18:54:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@571903e7,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Vb]
2015-09-25 18:54:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@571903e7,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.581608 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@571903e7,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Vb]
2015-09-25 18:54:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Wb]
2015-09-25 18:54:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:15 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.591597 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Wb]
2015-09-25 18:54:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@223d2289,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Xb]
2015-09-25 18:54:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@223d2289,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.767798 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@223d2289,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Xb]
2015-09-25 18:54:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Yb]
2015-09-25 18:54:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:25 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.641662 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Yb]
2015-09-25 18:54:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@585fc1f5,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Zb]
2015-09-25 18:54:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@585fc1f5,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.552145 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@585fc1f5,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$Zb]
2015-09-25 18:54:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$0b]
2015-09-25 18:54:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:35 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.290095 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$0b]
2015-09-25 18:54:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$1b]
2015-09-25 18:54:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(ExpireDeadHosts,true)
2015-09-25 18:54:37 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.614865 ms) AkkaMessage(ExpireDeadHosts,true) from Actor[akka://sparkDriver/temp/$1b]
2015-09-25 18:54:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@14d662c1,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$2b]
2015-09-25 18:54:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@14d662c1,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.255082 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@14d662c1,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$2b]
2015-09-25 18:54:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$3b]
2015-09-25 18:54:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:45 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.32957 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$3b]
2015-09-25 18:54:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@705fc6dc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$4b]
2015-09-25 18:54:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@705fc6dc,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.543957 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@705fc6dc,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$4b]
2015-09-25 18:54:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$5b]
2015-09-25 18:54:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:54:55 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.706828 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$5b]
2015-09-25 18:55:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7999f961,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$6b]
2015-09-25 18:55:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7999f961,BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:55:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.419657 ms) AkkaMessage(Heartbeat(driver,[Lscala.Tuple2;@7999f961,BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$6b]
2015-09-25 18:55:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:56 - [actor] received message AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$7b]
2015-09-25 18:55:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:63 - Received RPC message: AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true)
2015-09-25 18:55:05 DEBUG AkkaRpcEnv$$anonfun$actorRef$lzycompute$1$1$$anon$1:62 - [actor] handled message (0.542244 ms) AkkaMessage(BlockManagerHeartbeat(BlockManagerId(driver, localhost, 53087)),true) from Actor[akka://sparkDriver/temp/$7b]
